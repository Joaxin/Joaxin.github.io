<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Python Web Crawle Pt.8 - Scrapy | Pinsflora</title><meta name="keywords" content="scrapy"><meta name="author" content="Joaxin"><meta name="copyright" content="Joaxin"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Scrapy at a glance 1234567891011$ systeminfo | findstr &#x2F;B &#x2F;C:&quot;OS 名称&quot; &#x2F;C:&quot;OS 版本&quot;OS 名称:          Microsoft Windows 10 企业版OS 版本:          10.0.17763 暂缺 Build 17763$ conda env list# conda environments:#b">
<meta property="og:type" content="article">
<meta property="og:title" content="Python Web Crawle Pt.8 - Scrapy">
<meta property="og:url" content="https://u.pinsflora.xyz/Pysnista/Crawler/py_Crawler08_scrapy/index.html">
<meta property="og:site_name" content="Pinsflora">
<meta property="og:description" content="Scrapy at a glance 1234567891011$ systeminfo | findstr &#x2F;B &#x2F;C:&quot;OS 名称&quot; &#x2F;C:&quot;OS 版本&quot;OS 名称:          Microsoft Windows 10 企业版OS 版本:          10.0.17763 暂缺 Build 17763$ conda env list# conda environments:#b">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/joaxin/img_bed/img/cover/cover_red_dim_flower.jpg">
<meta property="article:published_time" content="2018-04-21T16:00:00.000Z">
<meta property="article:modified_time" content="2019-04-30T16:00:00.000Z">
<meta property="article:author" content="Joaxin">
<meta property="article:tag" content="scrapy">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/joaxin/img_bed/img/cover/cover_red_dim_flower.jpg"><link rel="shortcut icon" href="/img/favicon-32x32.png"><link rel="canonical" href="https://u.pinsflora.xyz/Pysnista/Crawler/py_Crawler08_scrapy/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script async="async" src="https://www.googletagmanager.com/gtag/js?id=UA-177831205-1"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-177831205-1');
</script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: {"limitDay":600,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: 'days',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"Traditional Chinese Activated Manually","cht_to_chs":"Simplified Chinese Activated Manually","day_to_night":"Dark Mode Activated Manually","night_to_day":"Light Mode Activated Manually","bgLight":"#49b1f5","bgDark":"#2d3035","position":"bottom-left"},
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2019-05-01 00:00:00'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><meta name="generator" content="Hexo 5.3.0"><link rel="alternate" href="/atom.xml" title="Pinsflora" type="application/atom+xml">
</head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="https://avatars2.githubusercontent.com/u/8346164?s=460&amp;v=4" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">340</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">110</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">34</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-list"></i><span> List</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/Galleries"><i class="fa-fw /gallery/"></i><span> 0</span></a></li><li><a class="site-page child" href="/Movie"><i class="fa-fw /movies/"></i><span> 1</span></a></li><li><a class="site-page child" href="/Games"><i class="fa-fw /games/"></i><span> 2</span></a></li><li><a class="site-page child" href="/Tools"><i class="fa-fw /tools/"></i><span> 3</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/joaxin/img_bed/img/cover/cover_red_dim_flower.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Pinsflora</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-list"></i><span> List</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/Galleries"><i class="fa-fw /gallery/"></i><span> 0</span></a></li><li><a class="site-page child" href="/Movie"><i class="fa-fw /movies/"></i><span> 1</span></a></li><li><a class="site-page child" href="/Games"><i class="fa-fw /games/"></i><span> 2</span></a></li><li><a class="site-page child" href="/Tools"><i class="fa-fw /tools/"></i><span> 3</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Python Web Crawle Pt.8 - Scrapy</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2018-04-21T16:00:00.000Z" title="Created 2018-04-22 00:00:00">2018-04-22</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2019-04-30T16:00:00.000Z" title="Updated 2019-05-01 00:00:00">2019-05-01</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Python/">Python</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Python/Crawler/">Crawler</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word count:</span><span class="word-count">4.5k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading time:</span><span>28min</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Python Web Crawle Pt.8 - Scrapy"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="scrapy-at-a-glance"><a class="markdownIt-Anchor" href="#scrapy-at-a-glance"></a> Scrapy at a glance</h2>
<figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ systeminfo | findstr /B /C:"OS 名称" /C:"OS 版本"</span><br><span class="line">OS 名称:          Microsoft Windows 10 企业版</span><br><span class="line">OS 版本:          10.0.17763 暂缺 Build 17763</span><br><span class="line">$ conda env list</span><br><span class="line"># conda environments:</span><br><span class="line">#</span><br><span class="line">base                     D:\Anaconda3</span><br><span class="line">bunnies               *  D:\Anaconda3\envs\bunnies</span><br><span class="line">crawler                  D:\Anaconda3\envs\crawler</span><br><span class="line">$ (crawler) G:\Python\jupyter&gt;scrapy version</span><br><span class="line">Scrapy 1.6.0</span><br></pre></td></tr></tbody></table></figure>
<p>Scrapy is an application framework for crawling web sites and extracting structured data which can be used for a wide range of useful applications, like <strong>data mining</strong>, <strong>information processing</strong> or <strong>historical archival</strong>.</p>
<p>In order to show you what Scrapy brings to the table, we’ll walk you through an example of a Scrapy Spider using the simplest way to run a spider.</p>
<p>Here’s the code for a spider that scrapes famous quotes from website <a target="_blank" rel="noopener" href="http://quotes.toscrape.com/">http://quotes.toscrape.com</a>, following the pagination:</p>
<figure class="highlight html"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"quote"</span> <span class="attr">itemscope</span>=<span class="string">""</span> <span class="attr">itemtype</span>=<span class="string">"http://schema.org/CreativeWork"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"text"</span> <span class="attr">itemprop</span>=<span class="string">"text"</span>&gt;</span>“A day without sunshine is like, you know, night.”<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">span</span>&gt;</span>by <span class="tag">&lt;<span class="name">small</span> <span class="attr">class</span>=<span class="string">"author"</span> <span class="attr">itemprop</span>=<span class="string">"author"</span>&gt;</span>Steve Martin<span class="tag">&lt;/<span class="name">small</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"/author/Steve-Martin"</span>&gt;</span>(about)<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"tags"</span>&gt;</span></span><br><span class="line">            Tags:</span><br><span class="line">            <span class="tag">&lt;<span class="name">meta</span> <span class="attr">class</span>=<span class="string">"keywords"</span> <span class="attr">itemprop</span>=<span class="string">"keywords"</span> <span class="attr">content</span>=<span class="string">"humor,obvious,simile"</span>&gt;</span> </span><br><span class="line">            <span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">"tag"</span> <span class="attr">href</span>=<span class="string">"/tag/humor/page/1/"</span>&gt;</span>humor<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">"tag"</span> <span class="attr">href</span>=<span class="string">"/tag/obvious/page/1/"</span>&gt;</span>obvious<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">"tag"</span> <span class="attr">href</span>=<span class="string">"/tag/simile/page/1/"</span>&gt;</span>simile<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">"quotes"</span></span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">'http://quotes.toscrape.com/tag/humor/'</span>,</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="keyword">for</span> quote <span class="keyword">in</span> response.css(<span class="string">'div.quote'</span>):</span><br><span class="line">            <span class="keyword">yield</span> {</span><br><span class="line">                <span class="string">'text'</span>: quote.css(<span class="string">'span.text::text'</span>).extract_first(),</span><br><span class="line">                <span class="string">'author'</span>: quote.xpath(<span class="string">'span/small/text()'</span>).extract_first(),</span><br><span class="line">            }</span><br><span class="line"></span><br><span class="line">        next_page = response.css(<span class="string">'li.next a::attr("href")'</span>).extract_first()</span><br><span class="line">        <span class="keyword">if</span> next_page <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">yield</span> response.follow(next_page, self.parse)</span><br></pre></td></tr></tbody></table></figure>
<p>Put this in a text file, name it to something like <code>quotes_spider.py</code> and run the spider using the <a target="_blank" rel="noopener" href="https://doc.scrapy.org/en/latest/topics/commands.html#std:command-runspider"><code>runspider</code></a> command:</p>
<figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy runspider quotes_spider.py -o quotes.json</span><br></pre></td></tr></tbody></table></figure>
<p>When this finishes you will have in the <code>quotes.json</code> file a list of the quotes in JSON format, containing text and author, looking like this (reformatted here for better readability):</p>
<p>That will generate an <code>quotes.json</code> file containing all scraped items, serialized in <code>JSON</code>.</p>
<figure class="highlight tex"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">{"text": "<span class="tag">\<span class="name">u</span></span>201cThe person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.<span class="tag">\<span class="name">u</span></span>201d", "author": "Jane Austen"},</span><br><span class="line">{"text": "<span class="tag">\<span class="name">u</span></span>201cA day without sunshine is like, you know, night.<span class="tag">\<span class="name">u</span></span>201d", "author": "Steve Martin"},</span><br><span class="line">{"text": "<span class="tag">\<span class="name">u</span></span>201cAnyone who thinks sitting in church can make you a Christian must also think that sitting in a garage can make you a car.<span class="tag">\<span class="name">u</span></span>201d", "author": "Garrison Keillor"},</span><br><span class="line">{"text": "<span class="tag">\<span class="name">u</span></span>201cBeauty is in the eye of the beholder and it may be necessary from time to time to give a stupid or misinformed beholder a black eye.<span class="tag">\<span class="name">u</span></span>201d", "author": "Jim Henson"},</span><br><span class="line">{"text": "<span class="tag">\<span class="name">u</span></span>201cAll you need is love. But a little chocolate now and then doesn't hurt.<span class="tag">\<span class="name">u</span></span>201d", "author": "Charles M. Schulz"},</span><br><span class="line">{"text": "<span class="tag">\<span class="name">u</span></span>201cRemember, we're madly in love, so it's all right to kiss me anytime you feel like it.<span class="tag">\<span class="name">u</span></span>201d", "author": "Suzanne Collins"},</span><br><span class="line">{"text": "<span class="tag">\<span class="name">u</span></span>201cSome people never go crazy. What truly horrible lives they must lead.<span class="tag">\<span class="name">u</span></span>201d", "author": "Charles Bukowski"},</span><br><span class="line">{"text": "<span class="tag">\<span class="name">u</span></span>201cThe trouble with having an open mind, of course, is that people will insist on coming along and trying to put things in it.<span class="tag">\<span class="name">u</span></span>201d", "author": "Terry Pratchett"},</span><br><span class="line">{"text": "<span class="tag">\<span class="name">u</span></span>201cThink left and think right and think low and think high. Oh, the thinks you can think up if only you try!<span class="tag">\<span class="name">u</span></span>201d", "author": "Dr. Seuss"},</span><br><span class="line">{"text": "<span class="tag">\<span class="name">u</span></span>201cThe reason I talk to myself is because I<span class="tag">\<span class="name">u</span></span>2019m the only one whose answers I accept.<span class="tag">\<span class="name">u</span></span>201d", "author": "George Carlin"},</span><br><span class="line">{"text": "<span class="tag">\<span class="name">u</span></span>201cI am free of all prejudice. I hate everyone equally. <span class="tag">\<span class="name">u</span></span>201d", "author": "W.C. Fields"},</span><br><span class="line">{"text": "<span class="tag">\<span class="name">u</span></span>201cA lady's imagination is very rapid; it jumps from admiration to love, from love to matrimony in a moment.<span class="tag">\<span class="name">u</span></span>201d", "author": "Jane Austen"}</span><br><span class="line">]</span><br></pre></td></tr></tbody></table></figure>
<p>For historic reasons, Scrapy appends to a given file instead of overwriting its contents. If you run this command twice without removing the file before the second time, you’ll end up with a broken JSON file.</p>
<p>You can also use other formats, like <a target="_blank" rel="noopener" href="http://jsonlines.org/">JSON Lines</a>:</p>
<figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl quotes -o quotes.jl</span><br></pre></td></tr></tbody></table></figure>
<p>The JSON Lines format is useful because it’s stream-like, you can easily append new records to it. It doesn’t have the same problem of JSON when you run twice. Also, as each record is a separate line, you can process big files without having to fit everything in memory, there are tools like <a target="_blank" rel="noopener" href="https://stedolan.github.io/jq">JQ</a> to help doing that at the command-line.</p>
<h3 id="things-that-are-good-to-know"><a class="markdownIt-Anchor" href="#things-that-are-good-to-know"></a> Things that are good to know</h3>
<p>Scrapy is written in pure Python and depends on a few key Python packages (among others):</p>
<ul>
<li><a target="_blank" rel="noopener" href="http://lxml.de/">lxml</a>, an efficient XML and HTML parser</li>
<li><a target="_blank" rel="noopener" href="https://pypi.python.org/pypi/parsel">parsel</a>, an HTML/XML data extraction library written on top of lxml,</li>
<li><a target="_blank" rel="noopener" href="https://pypi.python.org/pypi/w3lib">w3lib</a>, a multi-purpose helper for dealing with URLs and web page encodings</li>
<li><a target="_blank" rel="noopener" href="https://twistedmatrix.com/">twisted</a>, an asynchronous networking framework</li>
<li><a target="_blank" rel="noopener" href="https://cryptography.io/">cryptography</a> and <a target="_blank" rel="noopener" href="https://pypi.python.org/pypi/pyOpenSSL">pyOpenSSL</a>, to deal with various network-level security needs</li>
</ul>
<h2 id="scrapy-tutorial"><a class="markdownIt-Anchor" href="#scrapy-tutorial"></a> Scrapy Tutorial</h2>
<h3 id="creating-1st-project"><a class="markdownIt-Anchor" href="#creating-1st-project"></a> Creating 1st project</h3>
<p>Before you start scraping, you will have to set up a new Scrapy project.</p>
<p>Enter a directory where you’d like to store your code and run:</p>
<figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject rebirth</span><br></pre></td></tr></tbody></table></figure>
<p>This will create a <code>rebirth</code> directory with the following contents:</p>
<figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">$ cd rebirth</span><br><span class="line">$ tree /F</span><br><span class="line">G:.</span><br><span class="line">│  scrapy.cfg			# deploy configuration file</span><br><span class="line">│</span><br><span class="line">└─rebirth				# project's Python module, you'll import your code from here</span><br><span class="line">    │  items.py			# project items definition file</span><br><span class="line">    │  middlewares.py	# project middlewares file</span><br><span class="line">    │  pipelines.py 	# project pipelines file</span><br><span class="line">    │  settings.py		# project settings file</span><br><span class="line">    │  __init__.py		</span><br><span class="line">    │</span><br><span class="line">    ├─spiders			# a directory where you'll later put your spiders</span><br><span class="line">    │  │  __init__.py</span><br><span class="line">    │  │</span><br><span class="line">    │  └─__pycache__</span><br><span class="line">    └─__pycache__</span><br><span class="line">  </span><br></pre></td></tr></tbody></table></figure>
<h3 id="our-1st-spider"><a class="markdownIt-Anchor" href="#our-1st-spider"></a> Our 1st Spider</h3>
<p>Spiders are classes that you define and that Scrapy uses to scrape information from a website (or a group of websites). They must subclass <code>scrapy.Spider</code> and define the initial requests to make, optionally how to follow links in the pages, and how to parse the downloaded page content to extract data.</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rebirth/spiders</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">"quotes"</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span>(<span class="params">self</span>):</span></span><br><span class="line">        urls = [</span><br><span class="line">            <span class="string">'http://quotes.toscrape.com/page/1/'</span>,</span><br><span class="line">            <span class="string">'http://quotes.toscrape.com/page/2/'</span>,</span><br><span class="line">        ]</span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url=url, callback=self.parse)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        page = response.url.split(<span class="string">"/"</span>)[<span class="number">-2</span>]</span><br><span class="line">        filename = <span class="string">'quotes-%s.html'</span> % page</span><br><span class="line">        <span class="keyword">with</span> open(filename, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(response.body)</span><br><span class="line">        self.log(<span class="string">'Saved file %s'</span> % filename)</span><br></pre></td></tr></tbody></table></figure>
<p>As you can see, our Spider subclasses <a target="_blank" rel="noopener" href="https://doc.scrapy.org/en/latest/topics/spiders.html#scrapy.spiders.Spider"><code>scrapy.Spider</code></a> and defines some attributes and methods:</p>
<ul>
<li>
<p><a target="_blank" rel="noopener" href="https://doc.scrapy.org/en/latest/topics/spiders.html#scrapy.spiders.Spider.name"><code>name</code></a>: identifies the Spider. It must be unique within a project, that is, you can’t set the same name for different Spiders.</p>
</li>
<li>
<p><a target="_blank" rel="noopener" href="https://doc.scrapy.org/en/latest/topics/spiders.html#scrapy.spiders.Spider.start_requests"><code>start_requests()</code></a>: must return an iterable of Requests (you can return a list of requests or write a generator function) which the Spider will begin to crawl from. Subsequent requests will be generated successively from these initial requests.</p>
</li>
<li>
<p><a target="_blank" rel="noopener" href="https://doc.scrapy.org/en/latest/topics/spiders.html#scrapy.spiders.Spider.parse"><code>parse()</code></a>: a method that will be called to handle the response downloaded for each of the requests made. The response parameter is an instance of <a target="_blank" rel="noopener" href="https://doc.scrapy.org/en/latest/topics/request-response.html#scrapy.http.TextResponse"><code>TextResponse</code></a> that holds the page content and has further helpful methods to handle it.</p>
<p>The <a target="_blank" rel="noopener" href="https://doc.scrapy.org/en/latest/topics/spiders.html#scrapy.spiders.Spider.parse"><code>parse()</code></a> method usually parses the response, extracting the scraped data as dicts and also finding new URLs to follow and creating new requests (<a target="_blank" rel="noopener" href="https://doc.scrapy.org/en/latest/topics/request-response.html#scrapy.http.Request"><code>Request</code></a>) from them.</p>
</li>
</ul>
<p>Run the spider using <code>scrapy crawl quotes</code>,this command runs the spider with name <code>quotes</code> that we’ve just added, that will send some requests for the <code>quotes.toscrape.com</code> domain. You will get a file tree similar to this:</p>
<figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">G:.</span><br><span class="line">│  quotes-1.html</span><br><span class="line">│  quotes-2.html</span><br><span class="line">│  scrapy.cfg</span><br><span class="line">│</span><br><span class="line">└─rebirth</span><br><span class="line">    │  items.py</span><br><span class="line">    │  middlewares.py</span><br><span class="line">    │  pipelines.py</span><br><span class="line">    │  settings.py</span><br><span class="line">    │  __init__.py</span><br><span class="line">    │</span><br><span class="line">    ├─spiders</span><br><span class="line">    │  │  quotes_spider.py</span><br><span class="line">    │  │  __init__.py</span><br><span class="line">    │  │</span><br><span class="line">    │  └─__pycache__</span><br><span class="line">    │          quotes_spider.cpython-37.pyc</span><br><span class="line">    │          __init__.cpython-37.pyc</span><br><span class="line">    │</span><br><span class="line">    └─__pycache__</span><br><span class="line">            settings.cpython-37.pyc</span><br><span class="line">            __init__.cpython-37.pyc</span><br></pre></td></tr></tbody></table></figure>
<p>Instead of implementing a <a target="_blank" rel="noopener" href="https://doc.scrapy.org/en/latest/topics/spiders.html#scrapy.spiders.Spider.start_requests"><code>start_requests()</code></a> method that generates <a target="_blank" rel="noopener" href="https://doc.scrapy.org/en/latest/topics/request-response.html#scrapy.http.Request"><code>scrapy.Request</code></a> objects from URLs, you can just define a <a target="_blank" rel="noopener" href="https://doc.scrapy.org/en/latest/topics/spiders.html#scrapy.spiders.Spider.start_urls"><code>start_urls</code></a> class attribute with a list of URLs. This list will then be used by the default implementation of <a target="_blank" rel="noopener" href="https://doc.scrapy.org/en/latest/topics/spiders.html#scrapy.spiders.Spider.start_requests"><code>start_requests()</code></a> to create the initial requests for your spider:</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">"quotes"</span></span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">'http://quotes.toscrape.com/page/1/'</span>,</span><br><span class="line">        <span class="string">'http://quotes.toscrape.com/page/2/'</span>,</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        page = response.url.split(<span class="string">"/"</span>)[<span class="number">-2</span>]</span><br><span class="line">        filename = <span class="string">'quotes-%s.html'</span> % page</span><br><span class="line">        <span class="keyword">with</span> open(filename, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(response.body)</span><br></pre></td></tr></tbody></table></figure>
<p>The <a target="_blank" rel="noopener" href="https://doc.scrapy.org/en/latest/topics/spiders.html#scrapy.spiders.Spider.parse"><code>parse()</code></a> method will be called to handle each of the requests for those URLs, even though we haven’t explicitly told Scrapy to do so. This happens because <a target="_blank" rel="noopener" href="https://doc.scrapy.org/en/latest/topics/spiders.html#scrapy.spiders.Spider.parse"><code>parse()</code></a> is Scrapy’s default callback method, which is called for requests without an explicitly assigned callback.</p>
<h3 id="extracting-data"><a class="markdownIt-Anchor" href="#extracting-data"></a> Extracting data</h3>
<p>The best way to learn how to extract data with Scrapy is trying selectors using the shell <a target="_blank" rel="noopener" href="https://doc.scrapy.org/en/latest/topics/shell.html#topics-shell">Scrapy shell</a>. Run:</p>
<figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy shell "http://quotes.toscrape.com/page/1/" # For Win</span><br></pre></td></tr></tbody></table></figure>
<p>You will get:</p>
<figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[s] Available Scrapy objects:</span><br><span class="line">[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)</span><br><span class="line">[s]   crawler    &lt;scrapy.crawler.Crawler object at 0x0000024E0CDE0C50&gt;</span><br><span class="line">[s]   item       {}</span><br><span class="line">[s]   request    &lt;GET http://quotes.toscrape.com/page/1/&gt;</span><br><span class="line">[s]   response   &lt;200 http://quotes.toscrape.com/page/1/&gt;</span><br><span class="line">[s]   settings   &lt;scrapy.settings.Settings object at 0x0000024E0CDE0A20&gt;</span><br><span class="line">[s]   spider     &lt;DefaultSpider 'default' at 0x24e0d081278&gt;</span><br><span class="line">[s] Useful shortcuts:</span><br><span class="line">[s]   fetch(url[, redirect=True]) Fetch URL and update local objects (by default, redirects are followed)</span><br><span class="line">[s]   fetch(req)                  Fetch a scrapy.Request and update local objects</span><br><span class="line">[s]   shelp()           Shell help (print this help)</span><br><span class="line">[s]   view(response)    View response in a browser</span><br></pre></td></tr></tbody></table></figure>
<p>Using the shell, you can try selecting elements using CSS with the response object:</p>
<figure class="highlight powershell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">In</span> [<span class="number">1</span>]: response.css(<span class="string">'title'</span>)</span><br><span class="line">Out[<span class="number">1</span>]: [&lt;<span class="type">Selector</span> <span class="type">xpath</span>=<span class="string">'descendant-or-self::title'</span> <span class="type">data</span>=<span class="string">'&lt;title&gt;Quotes to Scrape&lt;/title&gt;'</span>&gt;]</span><br><span class="line"><span class="keyword">In</span> [<span class="number">2</span>]: response.css(<span class="string">'title'</span>).extract()</span><br><span class="line">Out[<span class="number">2</span>]: [<span class="string">'&lt;title&gt;Quotes to Scrape&lt;/title&gt;'</span>]</span><br><span class="line"><span class="keyword">In</span> [<span class="number">3</span>]: response.css(<span class="string">'title::text'</span>)</span><br><span class="line">Out[<span class="number">3</span>]: [&lt;<span class="type">Selector</span> <span class="type">xpath</span>=<span class="string">'descendant-or-self::title/text()'</span> <span class="type">data</span>=<span class="string">'Quotes to Scrape'</span>&gt;]</span><br><span class="line"><span class="keyword">In</span> [<span class="number">4</span>]: response.css(<span class="string">'title::text'</span>).extract()</span><br><span class="line">Out[<span class="number">4</span>]: [<span class="string">'Quotes to Scrape'</span>]</span><br></pre></td></tr></tbody></table></figure>
<p>As an alternative, you could’ve written:</p>
<figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">In [5]: response.css('title::text')[0].extract()</span><br><span class="line">Out[5]: 'Quotes to Scrape'</span><br><span class="line">In [6]: response.css('title::text').extract_first()</span><br><span class="line">Out[6]: 'Quotes to Scrape'</span><br></pre></td></tr></tbody></table></figure>
<p>Using <code>.extract_first()</code> avoids an <code>IndexError</code> and returns <code>None</code> when it doesn’t find any element matching the selection.</p>
<p>You can also use the <code>re()</code>method to extract using regular expressions:</p>
<figure class="highlight powershell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">In</span> [<span class="number">7</span>]: response.css(<span class="string">'title::text'</span>).re(<span class="built_in">r</span><span class="string">'Quotes.*'</span>)</span><br><span class="line">Out[<span class="number">7</span>]: [<span class="string">'Quotes to Scrape'</span>]</span><br><span class="line"><span class="keyword">In</span> [<span class="number">8</span>]: response.css(<span class="string">'title::text'</span>).re(<span class="built_in">r</span><span class="string">'Q\w+'</span>)</span><br><span class="line">Out[<span class="number">8</span>]: [<span class="string">'Quotes'</span>]</span><br><span class="line"><span class="keyword">In</span> [<span class="number">9</span>]: response.css(<span class="string">'title::text'</span>).re(<span class="built_in">r</span><span class="string">'(\w+) to (\w+)'</span>)</span><br><span class="line">Out[<span class="number">9</span>]: [<span class="string">'Quotes'</span>, <span class="string">'Scrape'</span>]</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">for quote in response.css("div.quote"):</span><br><span class="line">...     text = quote.css("span.text::text").extract_first()</span><br><span class="line">...     author = quote.css("small.author::text").extract_first()</span><br><span class="line">...     tags = quote.css("div.tags a.tag::text").extract()</span><br><span class="line">...     print(dict(text=text, author=author, tags=tags))</span><br></pre></td></tr></tbody></table></figure>
<p>You can also use the <code>xpath</code> method to extract using regular expressions:</p>
<p>Each quote in <a target="_blank" rel="noopener" href="http://quotes.toscrape.com/">http://quotes.toscrape.com</a> is represented by HTML elements that look like this:</p>
<p><code>Emmet</code>:</p>
<figure class="highlight"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">div.quote&gt;span.text{"The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking."}+(span{by}&gt;small.author+a[href="#"]{(about)})+div.tags{Tags:}&gt;a.tag[href="#"]{$$$}*4</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight html"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"quote"</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"text"</span>&gt;</span>"The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking."<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">span</span>&gt;</span>by<span class="tag">&lt;<span class="name">small</span> <span class="attr">class</span>=<span class="string">"author"</span>&gt;</span><span class="tag">&lt;/<span class="name">small</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"#"</span>&gt;</span>(about)<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"tags"</span>&gt;</span>Tags:</span><br><span class="line">		<span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"#"</span> <span class="attr">class</span>=<span class="string">"tag"</span>&gt;</span>001<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"#"</span> <span class="attr">class</span>=<span class="string">"tag"</span>&gt;</span>002<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"#"</span> <span class="attr">class</span>=<span class="string">"tag"</span>&gt;</span>003<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"#"</span> <span class="attr">class</span>=<span class="string">"tag"</span>&gt;</span>004<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight powershell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">In</span> [<span class="number">10</span>]: response.xpath(<span class="string">'//div[@class="quote"]//small/text()'</span>).extract_first()</span><br><span class="line">Out[<span class="number">10</span>]: <span class="string">'Albert Einstein'</span></span><br><span class="line"><span class="keyword">In</span> [<span class="number">11</span>]: response.xpath(<span class="string">'//span[@class="text"]/text()'</span>).extract_first()</span><br><span class="line">Out[<span class="number">11</span>]: <span class="string">'“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”'</span></span><br><span class="line"><span class="keyword">In</span> [<span class="number">12</span>]: response.xpath(<span class="string">'//div[@class="quote"][1]//a[@class="tag"]/text()'</span>).extract()</span><br><span class="line">Out[<span class="number">12</span>]: [<span class="string">'change'</span>, <span class="string">'deep-thoughts'</span>, <span class="string">'thinking'</span>, <span class="string">'world'</span>]</span><br></pre></td></tr></tbody></table></figure>
<h3 id="following-links"><a class="markdownIt-Anchor" href="#following-links"></a> Following links</h3>
<p>Let’s say, instead of just scraping the stuff from the first two pages from <a target="_blank" rel="noopener" href="http://quotes.toscrape.com/">http://quotes.toscrape.com</a>, you want quotes from all the pages in the website.</p>
<p>For that, Scrapy supports a CSS extension that let’s you select the attribute contents, like this:</p>
<figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">In [13]: response.css('li.next a::attr(href)').extract_first()</span><br><span class="line">Out[13]: '/page/2/'</span><br><span class="line">In [14]: response.xpath('//li[@class="next"]/a/@href').extract_first()</span><br><span class="line">Out[14]: '/page/2/'</span><br><span class="line">In [15]: response.css('li.next a')[0]</span><br><span class="line">Out[15]: &lt;Selector xpath="descendant-or-self::li[@class and contains(concat(' ', normalize-space(@class), ' '), ' next ')]/descendant-or-self::*/a" data='&lt;a href="/page/2/"&gt;Next &lt;span aria-hidde'&gt;</span><br><span class="line">In [16]: response.follow(response.css('li.next a')[0])</span><br><span class="line">Out[16]: &lt;GET http://quotes.toscrape.com/page/2/&gt;</span><br></pre></td></tr></tbody></table></figure>
<p>Let’s see now our spider modified to recursively follow the link to the next page, extracting data from it:</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">"quotes"</span></span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">'http://quotes.toscrape.com/page/1/'</span>,</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="keyword">for</span> quote <span class="keyword">in</span> response.css(<span class="string">'div.quote'</span>):</span><br><span class="line">            <span class="keyword">yield</span> {</span><br><span class="line">                <span class="string">'text'</span>: quote.css(<span class="string">'span.text::text'</span>).extract_first(),</span><br><span class="line">                <span class="string">'author'</span>: quote.css(<span class="string">'small.author::text'</span>).extract_first(),</span><br><span class="line">                <span class="string">'tags'</span>: quote.css(<span class="string">'div.tags a.tag::text'</span>).extract(),</span><br><span class="line">            }</span><br><span class="line"></span><br><span class="line">        next_page = response.css(<span class="string">'li.next a::attr(href)'</span>).extract_first()</span><br><span class="line">        <span class="keyword">if</span> next_page <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            next_page = response.urljoin(next_page)</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(next_page, callback=self.parse)</span><br></pre></td></tr></tbody></table></figure>
<p>As a shortcut for creating Request objects you can use response.follow:</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">next_page = response.css(<span class="string">'li.next a::attr(href)'</span>).extract_first()</span><br><span class="line"><span class="keyword">if</span> next_page <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">	<span class="keyword">yield</span> response.follow(next_page, callback=self.parse)</span><br></pre></td></tr></tbody></table></figure>
<p>Unlike scrapy.Request, <code>response.follow</code> supports relative URLs directly - no need to call urljoin. Note that <code>response.follow</code> just returns a Request instance; you still have to yield this Request.</p>
<p>You can also pass a selector to <code>response.follow</code> instead of a string; this selector should extract necessary attributes:</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> href <span class="keyword">in</span> response.css(<span class="string">'li.next a::attr(href)'</span>):</span><br><span class="line">    <span class="keyword">yield</span> response.follow(href, callback=self.parse)</span><br></pre></td></tr></tbody></table></figure>
<p>For <code>&lt;a&gt;</code> elements there is a shortcut: <code>response.follow</code> uses their href attribute automatically. So the code can be shortened further:</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> a <span class="keyword">in</span> response.css(<span class="string">'li.next a'</span>):</span><br><span class="line">	<span class="keyword">yield</span> response.follow(a, callback=self.parse)</span><br></pre></td></tr></tbody></table></figure>
<p>More simplicity:</p>
<figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">response.follow(response.css('li.next a')[0],callback=self.parse)</span><br></pre></td></tr></tbody></table></figure>
<p>In this  example, it creates a sort of loop, following all the links to the next page until it doesn’t find one – handy for crawling blogs, forums and other sites with pagination.</p>
<h3 id="scraping-author-information"><a class="markdownIt-Anchor" href="#scraping-author-information"></a> Scraping author information</h3>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AuthorSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">'author'</span></span><br><span class="line"></span><br><span class="line">    start_urls = [<span class="string">'http://quotes.toscrape.com/'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="comment"># follow links to author pages</span></span><br><span class="line">        <span class="keyword">for</span> href <span class="keyword">in</span> response.css(<span class="string">'.author + a::attr(href)'</span>):</span><br><span class="line">            <span class="keyword">yield</span> response.follow(href, self.parse_author)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># follow pagination links</span></span><br><span class="line">        <span class="keyword">for</span> href <span class="keyword">in</span> response.css(<span class="string">'li.next a::attr(href)'</span>):</span><br><span class="line">            <span class="keyword">yield</span> response.follow(href, self.parse)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_author</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">extract_with_css</span>(<span class="params">query</span>):</span></span><br><span class="line">            <span class="keyword">return</span> response.css(query).extract_first().strip()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">yield</span> {</span><br><span class="line">            <span class="string">'name'</span>: extract_with_css(<span class="string">'h3.author-title::text'</span>),</span><br><span class="line">            <span class="string">'birthdate'</span>: extract_with_css(<span class="string">'.author-born-date::text'</span>),</span><br><span class="line">            <span class="string">'bio'</span>: extract_with_css(<span class="string">'.author-description::text'</span>),</span><br><span class="line">        }</span><br></pre></td></tr></tbody></table></figure>
<p><code>scrapy crawl author -o author.json</code>:</p>
<figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">{"name": "Jane Austen", "birthdate": "December 16, 1775", "bio": "Jane Austen was an English novelist whose works of romantic fiction, set among the landed gentry, earned her a place as one of the most widely read writers in English literature, her realism and biting social commentary cementing her historical importance among scholars and critics.Austen lived her entire life as part of a close-knit family located on the lower fringes of the English landed gentry. She was educated primarily by her father and older brothers as well as through her own reading. The steadfast support of her family was critical to her development as a professional writer. Her artistic apprenticeship lasted from her teenage years until she was about 35 years old. During this period, she experimented with various literary forms, including the epistolary novel which she tried then abandoned, and wrote and extensively revised three major novels and began a fourth. From 1811 until 1816, with the release of Sense and Sensibility (1811), Pride and Prejudice (1813), Mansfield Park (1814) and Emma (1815), she achieved success as a published writer. She wrote two additional novels, Northanger Abbey and Persuasion, both published posthumously in 1818, and began a third, which was eventually titled Sanditon, but died before completing it.Austen's works critique the novels of sensibility of the second half of the 18th century and are part of the transition to 19th-century realism. Her plots, though fundamentally comic, highlight the dependence of women on marriage to secure social standing and economic security. Her work brought her little personal fame and only a few positive reviews during her lifetime, but the publication in 1869 of her nephew's A Memoir of Jane Austen introduced her to a wider public, and by the 1940s she had become widely accepted in academia as a great English writer. The second half of the 20th century saw a proliferation of Austen scholarship and the emergence of a Janeite fan culture."},</span><br><span class="line">....]</span><br></pre></td></tr></tbody></table></figure>
<p>The interesting thing this spider demonstrates is that, even if there are many quotes from the same author, we don’t need to worry about visiting the same author page multiple times. By default, Scrapy filters out duplicated requests to URLs already visited, avoiding the problem of hitting servers too much because of a programming mistake. This can be configured by the setting<a target="_blank" rel="noopener" href="https://doc.scrapy.org/en/latest/topics/settings.html#std:setting-DUPEFILTER_CLASS"><code>DUPEFILTER_CLASS</code></a>.</p>
<h3 id="using-spider-arguments"><a class="markdownIt-Anchor" href="#using-spider-arguments"></a> Using spider arguments</h3>
<p>You can provide command line arguments to your spiders by using the <code>-a</code> option when running them:</p>
<figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl quotes -o quotes-humor.json -a tag=humor</span><br></pre></td></tr></tbody></table></figure>
<p>These arguments are passed to the Spider’s <code>__init__</code> method and become spider attributes by default.</p>
<p>In this example, the value provided for the <code>tag</code> argument will be available via <code>self.tag</code>. You can use this to make your spider fetch only quotes with a specific tag, building the URL based on the argument:</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">"quotes"</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span>(<span class="params">self</span>):</span></span><br><span class="line">        url = <span class="string">'http://quotes.toscrape.com/'</span></span><br><span class="line">        tag = getattr(self, <span class="string">'tag'</span>, <span class="literal">None</span>)</span><br><span class="line">        <span class="keyword">if</span> tag <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            url = url + <span class="string">'tag/'</span> + tag</span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(url, self.parse)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="keyword">for</span> quote <span class="keyword">in</span> response.css(<span class="string">'div.quote'</span>):</span><br><span class="line">            <span class="keyword">yield</span> {</span><br><span class="line">                <span class="string">'text'</span>: quote.css(<span class="string">'span.text::text'</span>).extract_first(),</span><br><span class="line">                <span class="string">'author'</span>: quote.css(<span class="string">'small.author::text'</span>).extract_first(),</span><br><span class="line">            }</span><br><span class="line"></span><br><span class="line">        next_page = response.css(<span class="string">'li.next a::attr(href)'</span>).extract_first()</span><br><span class="line">        <span class="keyword">if</span> next_page <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">yield</span> response.follow(next_page, self.parse)</span><br></pre></td></tr></tbody></table></figure>
<p>If you pass the <code>tag=humor</code> argument to this spider, you’ll notice that it will only visit URLs from the <code>humor</code> tag, such as <code>http://quotes.toscrape.com/tag/humor</code>.</p>
<figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[{"text": "\u201cThe world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.\u201d", "author": "Albert Einstein"},</span><br><span class="line">{"text": "\u201cIt is our choices, Harry, that show what we truly are, far more than our abilities.\u201d", "author": "J.K. Rowling"},</span><br><span class="line">...</span><br></pre></td></tr></tbody></table></figure>
<p>By now, we have two spiders:</p>
<figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> scrapy list</span></span><br><span class="line">author</span><br><span class="line">quotes</span><br></pre></td></tr></tbody></table></figure>
<h2 id="command-line-tool"><a class="markdownIt-Anchor" href="#command-line-tool"></a> Command line tool</h2>
<p>Scrapy is controlled through the <code>scrapy</code> command-line tool, to be referred here as the “Scrapy tool” to differentiate it from the sub-commands, which we just call “commands” or “Scrapy commands”.</p>
<h3 id="configuration-settings"><a class="markdownIt-Anchor" href="#configuration-settings"></a> Configuration settings</h3>
<p>Scrapy will look for configuration parameters in ini-style <code>scrapy.cfg</code> files in standard locations:</p>
<ol>
<li><code>/etc/scrapy.cfg</code> or <code>c:\scrapy\scrapy.cfg</code> (system-wide),</li>
<li><code>~/.config/scrapy.cfg</code> (<code>$XDG_CONFIG_HOME</code>) and <code>~/.scrapy.cfg</code> (<code>$HOME</code>) for global (user-wide) settings, and</li>
<li><code>scrapy.cfg</code> inside a scrapy project’s root</li>
</ol>
<p>Settings from these files are merged in the listed order of preference: user-defined values have higher priority than system-wide defaults and project-wide settings will override all others, when defined.</p>
<h3 id="available-tool-commands"><a class="markdownIt-Anchor" href="#available-tool-commands"></a> Available tool commands</h3>
<h4 id="startproject"><a class="markdownIt-Anchor" href="#startproject"></a> startproject</h4>
<ul>
<li>Syntax: <code>scrapy startproject &lt;project_name&gt; [project_dir]</code></li>
</ul>
<p>Creates a new Scrapy project named <code>project_name</code>, under the <code>project_dir</code> directory. If <code>project_dir</code>wasn’t specified, <code>project_dir</code> will be the same as <code>project_name</code>.</p>
<p>Usage example:</p>
<figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy startproject myproject</span><br></pre></td></tr></tbody></table></figure>
<h4 id="genspider"><a class="markdownIt-Anchor" href="#genspider"></a> genspider</h4>
<ul>
<li>Syntax: <code>scrapy genspider [-t template] &lt;name&gt; &lt;domain&gt;</code></li>
</ul>
<p>Create a new spider in the current folder or in the current project’s <code>spiders</code> folder, if called from inside a project. The <code>&lt;name&gt;</code> parameter is set as the spider’s <code>name</code>, while <code>&lt;domain&gt;</code> is used to generate the <code>allowed_domains</code> and <code>start_urls</code> spider’s attributes.</p>
<p>Usage example:</p>
<figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy genspider -l</span><br><span class="line">Available templates:</span><br><span class="line">  basic</span><br><span class="line">  crawl</span><br><span class="line">  csvfeed</span><br><span class="line">  xmlfeed</span><br><span class="line"></span><br><span class="line">$ scrapy genspider example example.com</span><br><span class="line">Created spider 'example' using template 'basic'</span><br><span class="line"></span><br><span class="line">$ scrapy genspider -t crawl scrapyorg scrapy.org</span><br><span class="line">Created spider 'scrapyorg' using template 'crawl'</span><br></pre></td></tr></tbody></table></figure>
<p>This is just a convenience shortcut command for creating spiders based on pre-defined templates, but certainly not the only way to create spiders. You can just create the spider source code files yourself, instead of using this command.</p>
<h4 id="crawl"><a class="markdownIt-Anchor" href="#crawl"></a> crawl</h4>
<ul>
<li>Syntax: <code>scrapy crawl &lt;spider&gt;</code></li>
<li>Requires project: <em>yes</em></li>
</ul>
<p>Start crawling using a spider.</p>
<p>Usage examples:</p>
<figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy crawl myspider</span><br><span class="line">[ ... myspider starts crawling ... ]</span><br></pre></td></tr></tbody></table></figure>
<h4 id="check"><a class="markdownIt-Anchor" href="#check"></a> check</h4>
<ul>
<li>Syntax: <code>scrapy check [-l] &lt;spider&gt;</code></li>
<li>Requires project: <em>yes</em></li>
</ul>
<p>Run contract checks.</p>
<p>Usage examples:</p>
<figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy check -l</span><br><span class="line">first_spider</span><br><span class="line">  * parse</span><br><span class="line">  * parse_item</span><br><span class="line">second_spider</span><br><span class="line">  * parse</span><br><span class="line">  * parse_item</span><br><span class="line"></span><br><span class="line">$ scrapy check</span><br><span class="line">[FAILED] first_spider:parse_item</span><br><span class="line">&gt;&gt;&gt; 'RetailPricex' field is missing</span><br><span class="line"></span><br><span class="line">[FAILED] first_spider:parse</span><br><span class="line">&gt;&gt;&gt; Returned 92 requests, expected 0..4</span><br></pre></td></tr></tbody></table></figure>
<h4 id="list"><a class="markdownIt-Anchor" href="#list"></a> list</h4>
<ul>
<li>Syntax: <code>scrapy list</code></li>
<li>Requires project: <em>yes</em></li>
</ul>
<p>List all available spiders in the current project. The output is one spider per line.</p>
<p>Usage example:</p>
<figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy list</span><br><span class="line">spider1</span><br><span class="line">spider2</span><br></pre></td></tr></tbody></table></figure>
<h4 id="fetch"><a class="markdownIt-Anchor" href="#fetch"></a> fetch</h4>
<ul>
<li>Syntax: <code>scrapy fetch &lt;url&gt;</code></li>
<li>Requires project: <em>no</em></li>
</ul>
<p>Downloads the given URL using the Scrapy downloader and writes the contents to standard output.</p>
<p>The interesting thing about this command is that it fetches the page how the spider would download it. For example, if the spider has a <code>USER_AGENT</code> attribute which overrides the User Agent, it will use that one.</p>
<p>So this command can be used to “see” how your spider would fetch a certain page.</p>
<p>Supported options:</p>
<ul>
<li><code>--spider=SPIDER</code>: bypass spider autodetection and force use of specific spider</li>
<li><code>--headers</code>: print the response’s HTTP headers instead of the response’s body</li>
<li><code>--no-redirect</code>: do not follow HTTP 3xx redirects (default is to follow them)</li>
</ul>
<p>Usage examples:</p>
<figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy fetch --nolog http://www.example.com/some/page.html</span><br><span class="line">[ ... html content here ... ]</span><br><span class="line"></span><br><span class="line">$ scrapy fetch --nolog --headers http://www.example.com/</span><br><span class="line">{'Accept-Ranges': ['bytes'],</span><br><span class="line"> 'Age': ['1263   '],</span><br><span class="line"> 'Connection': ['close     '],</span><br><span class="line"> 'Content-Length': ['596'],</span><br><span class="line"> 'Content-Type': ['text/html; charset=UTF-8'],</span><br><span class="line"> 'Date': ['Wed, 18 Aug 2010 23:59:46 GMT'],</span><br><span class="line"> 'Etag': ['"573c1-254-48c9c87349680"'],</span><br><span class="line"> 'Last-Modified': ['Fri, 30 Jul 2010 15:30:18 GMT'],</span><br><span class="line"> 'Server': ['Apache/2.2.3 (CentOS)']}</span><br></pre></td></tr></tbody></table></figure>
<h4 id="view"><a class="markdownIt-Anchor" href="#view"></a> view</h4>
<ul>
<li>Syntax: <code>scrapy view &lt;url&gt;</code></li>
<li>Requires project: <em>no</em></li>
</ul>
<p>Opens the given URL in a browser, as your Scrapy spider would “see” it. Sometimes spiders see pages differently from regular users, so this can be used to check what the spider “sees” and confirm it’s what you expect.</p>
<p>Supported options:</p>
<ul>
<li><code>--spider=SPIDER</code>: bypass spider autodetection and force use of specific spider</li>
<li><code>--no-redirect</code>: do not follow HTTP 3xx redirects (default is to follow them)</li>
</ul>
<p>Usage example:</p>
<figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy view http://www.example.com/some/page.html</span><br><span class="line">[ ... browser starts ... ]</span><br></pre></td></tr></tbody></table></figure>
<h4 id="shell"><a class="markdownIt-Anchor" href="#shell"></a> shell</h4>
<ul>
<li>Syntax: <code>scrapy shell [url]</code></li>
<li>Requires project: <em>no</em></li>
</ul>
<p>Starts the Scrapy shell for the given URL (if given) or empty if no URL is given. Also supports UNIX-style local file paths, either relative with <code>./</code> or <code>../</code> prefixes or absolute file paths.</p>
<p>Supported options:</p>
<ul>
<li><code>--spider=SPIDER</code>: bypass spider autodetection and force use of specific spider</li>
<li><code>-c code</code>: evaluate the code in the shell, print the result and exit</li>
<li><code>--no-redirect</code>: do not follow HTTP 3xx redirects (default is to follow them); this only affects the URL you may pass as argument on the command line; once you are inside the shell, <code>fetch(url)</code>will still follow HTTP redirects by default.</li>
</ul>
<p>Usage example:</p>
<figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy shell http://www.example.com/some/page.html</span><br><span class="line">[ ... scrapy shell starts ... ]</span><br><span class="line"></span><br><span class="line">$ scrapy shell --nolog http://www.example.com/ -c '(response.status, response.url)'</span><br><span class="line">(200, 'http://www.example.com/')</span><br><span class="line"></span><br><span class="line"># shell follows HTTP redirects by default</span><br><span class="line">$ scrapy shell --nolog http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F -c '(response.status, response.url)'</span><br><span class="line">(200, 'http://example.com/')</span><br><span class="line"></span><br><span class="line"># you can disable this with --no-redirect</span><br><span class="line"># (only for the URL passed as command line argument)</span><br><span class="line">$ scrapy shell --no-redirect --nolog http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F -c '(response.status, response.url)'</span><br><span class="line">(302, 'http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F')</span><br></pre></td></tr></tbody></table></figure>
<h4 id="parse"><a class="markdownIt-Anchor" href="#parse"></a> parse</h4>
<ul>
<li>Syntax: <code>scrapy parse &lt;url&gt; [options]</code></li>
<li>Requires project: <em>yes</em></li>
</ul>
<p>Fetches the given URL and parses it with the spider that handles it, using the method passed with the <code>--callback</code> option, or <code>parse</code> if not given.</p>
<p>Supported options:</p>
<ul>
<li><code>--spider=SPIDER</code>: bypass spider autodetection and force use of specific spider</li>
<li><code>--a NAME=VALUE</code>: set spider argument (may be repeated)</li>
<li><code>--callback</code> or <code>-c</code>: spider method to use as callback for parsing the response</li>
<li><code>--meta</code> or <code>-m</code>: additional request meta that will be passed to the callback request. This must be a valid json string. Example: –meta=’{“foo” : “bar”}’</li>
<li><code>--pipelines</code>: process items through pipelines</li>
<li><code>--rules</code> or <code>-r</code>: use <a target="_blank" rel="noopener" href="https://doc.scrapy.org/en/latest/topics/spiders.html#scrapy.spiders.CrawlSpider"><code>CrawlSpider</code></a> rules to discover the callback (i.e. spider method) to use for parsing the response</li>
<li><code>--noitems</code>: don’t show scraped items</li>
<li><code>--nolinks</code>: don’t show extracted links</li>
<li><code>--nocolour</code>: avoid using pygments to colorize the output</li>
<li><code>--depth</code> or <code>-d</code>: depth level for which the requests should be followed recursively (default: 1)</li>
<li><code>--verbose</code> or <code>-v</code>: display information for each depth level</li>
</ul>
<p>Usage example:</p>
<figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy parse http://www.example.com/ -c parse_item</span><br><span class="line">[ ... scrapy log lines crawling example.com spider ... ]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; STATUS DEPTH LEVEL 1 &lt;&lt;&lt;</span><br><span class="line"># Scraped Items  ------------------------------------------------------------</span><br><span class="line">[{'name': u'Example item',</span><br><span class="line"> 'category': u'Furniture',</span><br><span class="line"> 'length': u'12 cm'}]</span><br><span class="line"></span><br><span class="line"># Requests  -----------------------------------------------------------------</span><br><span class="line">[]</span><br></pre></td></tr></tbody></table></figure>
<h4 id="settings"><a class="markdownIt-Anchor" href="#settings"></a> settings</h4>
<ul>
<li>Syntax: <code>scrapy settings [options]</code></li>
<li>Requires project: <em>no</em></li>
</ul>
<p>Get the value of a Scrapy setting.</p>
<p>If used inside a project it’ll show the project setting value, otherwise it’ll show the default Scrapy value for that setting.</p>
<p>Example usage:</p>
<figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy settings --get BOT_NAME</span><br><span class="line">scrapybot</span><br><span class="line">$ scrapy settings --get DOWNLOAD_DELAY</span><br><span class="line">0</span><br></pre></td></tr></tbody></table></figure>
<h4 id="runspider"><a class="markdownIt-Anchor" href="#runspider"></a> runspider</h4>
<ul>
<li>Syntax: <code>scrapy runspider &lt;spider_file.py&gt;</code></li>
<li>Requires project: <em>no</em></li>
</ul>
<p>Run a spider self-contained in a Python file, without having to create a project.</p>
<p>Example usage:</p>
<figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy runspider myspider.py</span><br><span class="line">[ ... spider starts crawling ... ]</span><br></pre></td></tr></tbody></table></figure>
<h4 id="version"><a class="markdownIt-Anchor" href="#version"></a> version</h4>
<ul>
<li>Syntax: <code>scrapy version [-v]</code></li>
<li>Requires project: <em>no</em></li>
</ul>
<p>Prints the Scrapy version. If used with <code>-v</code> it also prints Python, Twisted and Platform info, which is useful for bug reports.</p>
<h2 id="references"><a class="markdownIt-Anchor" href="#references"></a> REFERENCES</h2>
<ul>
<li><a target="_blank" rel="noopener" href="https://doc.scrapy.org/en/latest/intro/overview.html">https://doc.scrapy.org/en/latest/intro/overview.html</a></li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">Joaxin</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://u.pinsflora.xyz/Pysnista/Crawler/py_Crawler08_scrapy/">https://u.pinsflora.xyz/Pysnista/Crawler/py_Crawler08_scrapy/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/scrapy/">scrapy</a></div><div class="post_share"><div class="addtoany"><div class="a2a_kit a2a_kit_size_32 a2a_default_style"><a class="a2a_button_facebook"></a><a class="a2a_button_twitter"></a><a class="a2a_button_wechat"></a><a class="a2a_button_sina_weibo"></a><a class="a2a_button_facebook_messenger"></a><a class="a2a_button_email"></a><a class="a2a_button_copy_link"></a><a class="a2a_dd" target="_blank" rel="noopener" href="https://www.addtoany.com/share"></a></div></div><script async="async" src="https://static.addtoany.com/menu/page.js"></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/Life/thinking/life_thinking/"><img class="prev-cover" src="https://cdn.jsdelivr.net/gh/joaxin/img_bed/img/cover/cover_tree_dawnlights.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">胡思乱想？？</div></div></a></div><div class="next-post pull-right"><a href="/Lang/jp/duo_jp001_intro/"><img class="next-cover" src="https://cdn.jsdelivr.net/gh/joaxin/img_bed/img/cover_posts/duo/duolingo_jp_.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">Japanese - Vol.1 - Introduction</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="https://avatars2.githubusercontent.com/u/8346164?s=460&amp;v=4" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">Joaxin</div><div class="author-info__description">When I close my eyes, I'm in my own ♡cean 🐟aves.</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">340</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">110</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">34</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/joaxin"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/joaxin" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:lotility@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="/atom.xml" target="_blank" title="RSS"><i class="fas fa-rss"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">感謝訪問本站，若喜歡請收藏 ^_^</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#scrapy-at-a-glance"><span class="toc-number">1.</span> <span class="toc-text"> Scrapy at a glance</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#things-that-are-good-to-know"><span class="toc-number">1.1.</span> <span class="toc-text"> Things that are good to know</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#scrapy-tutorial"><span class="toc-number">2.</span> <span class="toc-text"> Scrapy Tutorial</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#creating-1st-project"><span class="toc-number">2.1.</span> <span class="toc-text"> Creating 1st project</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#our-1st-spider"><span class="toc-number">2.2.</span> <span class="toc-text"> Our 1st Spider</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#extracting-data"><span class="toc-number">2.3.</span> <span class="toc-text"> Extracting data</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#following-links"><span class="toc-number">2.4.</span> <span class="toc-text"> Following links</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#scraping-author-information"><span class="toc-number">2.5.</span> <span class="toc-text"> Scraping author information</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#using-spider-arguments"><span class="toc-number">2.6.</span> <span class="toc-text"> Using spider arguments</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#command-line-tool"><span class="toc-number">3.</span> <span class="toc-text"> Command line tool</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#configuration-settings"><span class="toc-number">3.1.</span> <span class="toc-text"> Configuration settings</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#available-tool-commands"><span class="toc-number">3.2.</span> <span class="toc-text"> Available tool commands</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#startproject"><span class="toc-number">3.2.1.</span> <span class="toc-text"> startproject</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#genspider"><span class="toc-number">3.2.2.</span> <span class="toc-text"> genspider</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#crawl"><span class="toc-number">3.2.3.</span> <span class="toc-text"> crawl</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#check"><span class="toc-number">3.2.4.</span> <span class="toc-text"> check</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#list"><span class="toc-number">3.2.5.</span> <span class="toc-text"> list</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#fetch"><span class="toc-number">3.2.6.</span> <span class="toc-text"> fetch</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#view"><span class="toc-number">3.2.7.</span> <span class="toc-text"> view</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#shell"><span class="toc-number">3.2.8.</span> <span class="toc-text"> shell</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#parse"><span class="toc-number">3.2.9.</span> <span class="toc-text"> parse</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#settings"><span class="toc-number">3.2.10.</span> <span class="toc-text"> settings</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#runspider"><span class="toc-number">3.2.11.</span> <span class="toc-text"> runspider</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#version"><span class="toc-number">3.2.12.</span> <span class="toc-text"> version</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#references"><span class="toc-number">4.</span> <span class="toc-text"> REFERENCES</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/Lang/es/duo_es/" title="No title"><img src="https://cdn.jsdelivr.net/gh/joaxin/img_bed/img/cover/cover_seeds.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="No title"/></a><div class="content"><a class="title" href="/Lang/es/duo_es/" title="No title">No title</a><time datetime="2020-06-29T03:44:49.224Z" title="Created 2020-06-29 11:44:49">2020-06-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/Lang/kl/duo_kl001_intro/" title="Klingon- Vol.1 - Introduction"><img src="https://cdn.jsdelivr.net/gh/joaxin/img_bed/img/cover/cover_little_girl_phone.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Klingon- Vol.1 - Introduction"/></a><div class="content"><a class="title" href="/Lang/kl/duo_kl001_intro/" title="Klingon- Vol.1 - Introduction">Klingon- Vol.1 - Introduction</a><time datetime="2020-06-26T16:00:00.000Z" title="Created 2020-06-27 00:00:00">2020-06-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/Life/apps/life_apps_android_list/" title="安卓 | 装机必备清单及习惯步骤"><img src="https://i.postimg.cc/KYPmhV8w/android-new-logo.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="安卓 | 装机必备清单及习惯步骤"/></a><div class="content"><a class="title" href="/Life/apps/life_apps_android_list/" title="安卓 | 装机必备清单及习惯步骤">安卓 | 装机必备清单及习惯步骤</a><time datetime="2020-06-20T04:29:10.462Z" title="Created 2020-06-20 12:29:10">2020-06-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/Pysnista/Intro/files/py_pillow/" title="Python - 操作图像"><img src="https://cdn.jsdelivr.net/gh/joaxin/img_bed/img/cover/cover_little_girl_phone.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Python - 操作图像"/></a><div class="content"><a class="title" href="/Pysnista/Intro/files/py_pillow/" title="Python - 操作图像">Python - 操作图像</a><time datetime="2020-05-02T16:00:00.000Z" title="Created 2020-05-03 00:00:00">2020-05-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/Pysnista/Intro/files/py_files_pdf_word/" title="Python - PDF &amp; Word"><img src="https://i.loli.net/2020/07/09/6ALoRXnITgcuvy2.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Python - PDF &amp; Word"/></a><div class="content"><a class="title" href="/Pysnista/Intro/files/py_files_pdf_word/" title="Python - PDF &amp; Word">Python - PDF &amp; Word</a><time datetime="2020-04-12T16:00:00.000Z" title="Created 2020-04-13 00:00:00">2020-04-13</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://cdn.jsdelivr.net/gh/joaxin/img_bed/img/cover/cover_red_dim_flower.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By Joaxin</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Refine, the Life</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="Increase font size"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="Decrease font size"><i class="fas fa-minus"></i></button><button id="translateLink" type="button" title="Switch Between Traditional Chinese And Simplified Chinese">繁</button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="chat_btn" type="button" title="rightside.chat_btn"><i class="fas fa-sms"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (document.getElementsByClassName('mermaid').length) {
  if (window.mermaidJsLoad) mermaid.init()
  else {
    getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(() => {
      window.mermaidJsLoad = true
      mermaid.initialize({
        theme: 'default',
      })
      false && mermaid.init()
    })
  }
}</script></div><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="fasle"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script>(function(i,s,o,g,r,a,m){i["DaoVoiceObject"]=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;a.charset="utf-8";m.parentNode.insertBefore(a,m)})(window,document,"script",('https:' == document.location.protocol ? 'https:' : 'http:') + "//widget.daovoice.io/widget/fae45343.js","daovoice")
</script><script>var isChatBtn = true
daovoice('init', {
  app_id: 'fae45343',},{
  launcher: { 
     disableLauncherIcon: isChatBtn // 悬浮 ICON 是否显示
  },
});
daovoice('update');

if (isChatBtn) {
  var chatBtnFn = () => {
    var chatBtn = document.getElementById("chat_btn")
    chatBtn.addEventListener("click", function(){
      daovoice('show')
    });
  }
  chatBtnFn()
} else {
  if (true) {
    function chatBtnHide () {
      daovoice('update', {},{
        launcher: { 
        disableLauncherIcon: true // 悬浮 ICON 是否显示
        },
      });
    }
    function chatBtnShow () {
      daovoice('update', {},{
        launcher: { 
        disableLauncherIcon: false // 悬浮 ICON 是否显示
        },
      });
    }
  }
}</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>