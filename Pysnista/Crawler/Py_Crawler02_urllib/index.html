<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Python Web Crawler 2 - Urllib | Pinsflora</title><meta name="keywords" content="Crawler"><meta name="author" content="Joaxin"><meta name="copyright" content="Joaxin"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Usage for python built-in urlib.">
<meta property="og:type" content="article">
<meta property="og:title" content="Python Web Crawler 2 - Urllib">
<meta property="og:url" content="https://u.pinsflora.xyz/Pysnista/Crawler/Py_Crawler02_urllib/index.html">
<meta property="og:site_name" content="Pinsflora">
<meta property="og:description" content="Usage for python built-in urlib.">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://cdn.pixabay.com/photo/2020/09/23/19/58/halloween-5596921__340.jpg">
<meta property="article:published_time" content="2017-12-16T16:00:00.000Z">
<meta property="article:modified_time" content="2020-10-28T16:00:00.000Z">
<meta property="article:author" content="Joaxin">
<meta property="article:tag" content="Crawler">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.pixabay.com/photo/2020/09/23/19/58/halloween-5596921__340.jpg"><link rel="shortcut icon" href="/img/favicon-32x32.png"><link rel="canonical" href="https://u.pinsflora.xyz/Pysnista/Crawler/Py_Crawler02_urllib/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script async="async" src="https://www.googletagmanager.com/gtag/js?id=UA-177831205-1"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-177831205-1');
</script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: {"limitDay":600,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: 'days',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"Traditional Chinese Activated Manually","cht_to_chs":"Simplified Chinese Activated Manually","day_to_night":"Dark Mode Activated Manually","night_to_day":"Light Mode Activated Manually","bgLight":"#49b1f5","bgDark":"#2d3035","position":"bottom-left"},
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2020-10-29 00:00:00'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><meta name="generator" content="Hexo 5.3.0"><link rel="alternate" href="/atom.xml" title="Pinsflora" type="application/atom+xml">
</head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="https://avatars2.githubusercontent.com/u/8346164?s=460&amp;v=4" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">340</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">110</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">34</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-list"></i><span> List</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/Galleries"><i class="fa-fw /gallery/"></i><span> 0</span></a></li><li><a class="site-page child" href="/Movie"><i class="fa-fw /movies/"></i><span> 1</span></a></li><li><a class="site-page child" href="/Games"><i class="fa-fw /games/"></i><span> 2</span></a></li><li><a class="site-page child" href="/Tools"><i class="fa-fw /tools/"></i><span> 3</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.pixabay.com/photo/2020/09/23/19/58/halloween-5596921__340.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Pinsflora</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-list"></i><span> List</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/Galleries"><i class="fa-fw /gallery/"></i><span> 0</span></a></li><li><a class="site-page child" href="/Movie"><i class="fa-fw /movies/"></i><span> 1</span></a></li><li><a class="site-page child" href="/Games"><i class="fa-fw /games/"></i><span> 2</span></a></li><li><a class="site-page child" href="/Tools"><i class="fa-fw /tools/"></i><span> 3</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Python Web Crawler 2 - Urllib</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2017-12-16T16:00:00.000Z" title="Created 2017-12-17 00:00:00">2017-12-17</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2020-10-28T16:00:00.000Z" title="Updated 2020-10-29 00:00:00">2020-10-29</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Python/">Python</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Python/Crawler/">Crawler</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word count:</span><span class="word-count">3.2k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading time:</span><span>15min</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Python Web Crawler 2 - Urllib"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>urllib 库 是 Python内置的 一个HTTP 请求库，虽然功能没有requests模块智能，但由于是内置的标准库，在一些简单的场景使用还是十分方便的和强大的。</p>
<p>它提供了以下几种模块：</p>
<ol>
<li>
<p>urllib.request 请求模块(or opening and reading URLs)</p>
</li>
<li>
<p>urllib.error 异常处理模块(containing the exceptions raised by urllib.request)</p>
</li>
<li>
<p>urllib.parse url 解析模块(for parsing URLs)</p>
</li>
<li>
<p>urllib.robotparser 解析robots.txt 模块(for parsing <code>robots.txt</code> files)</p>
</li>
</ol>
<h2 id="http请求request"><a class="markdownIt-Anchor" href="#http请求request"></a> HTTP请求Request</h2>
<p>首先，我们来看一下最常用的requests模块, 用于模拟浏览器发起一个 HTTP 请求，参数如下：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">urllib.request.urlopen(url, data=<span class="literal">None</span>, [timeout, ]*, cafile=<span class="literal">None</span>, capath=<span class="literal">None</span>, context=<span class="literal">None</span>)</span><br><span class="line"><span class="comment"># url： 网址</span></span><br><span class="line"><span class="comment"># data： bytes类型的内容，以POST方式提交表单。使用标准格式是application/x-www-form-urlencoded</span></span><br><span class="line"><span class="comment"># timeout：设置请求超时时间，比如：timeout=1 (1s后自动time out)</span></span><br><span class="line"><span class="comment"># cafile和capath： CA 证书和 CA 证书的路径</span></span><br><span class="line"><span class="comment"># context：ssl设置</span></span><br><span class="line">urllib.request.Request(url, data=<span class="literal">None</span>, headers={}, origin_req_host=<span class="literal">None</span>, unverifiable=<span class="literal">False</span>, method=<span class="literal">None</span>)</span><br><span class="line"><span class="comment"># 同urlopen</span></span><br><span class="line"><span class="comment"># headers：可修改请求头，还可使用add_header()方法修改请求头</span></span><br><span class="line"><span class="comment"># origin_req_host： 请求方的host名称或者IP地址。</span></span><br><span class="line"><span class="comment"># unverifiable： 请求是否是无法验证的，默认值是False。</span></span><br><span class="line"><span class="comment"># method： HTTP 请求的方式</span></span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getPage</span>(<span class="params">url</span>):</span></span><br><span class="line">    page = urllib.request.urlopen(url) </span><br><span class="line">    print(page)</span><br><span class="line">    <span class="comment">## 返回结果一个http.client.HTTPResponse对象</span></span><br><span class="line">    print(type(page))</span><br><span class="line">    print(page.status)</span><br><span class="line">    print(page.getheaders())</span><br><span class="line">    <span class="comment">##  获取页面源代码并转换为utf-8编码</span></span><br><span class="line">    <span class="keyword">return</span> page.read().decode(<span class="string">'utf-8'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 测试一个网址</span></span><br><span class="line">getPage(<span class="string">"https://docs.python.org/3/library/urllib.html"</span>)</span><br><span class="line"><span class="comment"># &lt;http.client.HTTPResponse object at 0x0000000004E56748&gt;</span></span><br><span class="line"><span class="comment"># &lt;class 'http.client.HTTPResponse'&gt;</span></span><br><span class="line"><span class="comment"># 200</span></span><br><span class="line"><span class="comment"># [('Connection', 'close'), ('Content-Length', '9530'), ('Server', 'nginx'), ('Content-Type', 'text/html')...</span></span><br><span class="line"><span class="comment"># '\n&lt;!DOCTYPE html&gt;\n\n&lt;html xmlns="http://www.w3.org/1999/xhtml"&gt;\n  &lt;h...</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 测试一张图片</span></span><br><span class="line">getPage(<span class="string">"https://cdn.pixabay.com/photo/2020/09/23/19/58/halloween-5596921__340.jpg"</span>)</span><br><span class="line"><span class="comment"># HTTP Error 403: Forbidden</span></span><br></pre></td></tr></tbody></table></figure>
<p>发现requests请求被禁止，此时我们需要使用Requests模拟一个请求头，如下：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">headers = {</span><br><span class="line">    <span class="string">'USER-AGENT'</span>:<span class="string">'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.111 Safari/537.36'</span></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getPage</span>(<span class="params">url</span>):</span></span><br><span class="line">    page = urllib.request.Request(url, headers=headers)</span><br><span class="line">    print(page)</span><br><span class="line">    print(type(page))</span><br><span class="line">    page = urllib.request.urlopen(page) </span><br><span class="line">    print(page.getheaders())</span><br><span class="line">    <span class="keyword">return</span> page.read()</span><br></pre></td></tr></tbody></table></figure>
<p>此时输入以上图片地址，输出为：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># &lt;urllib.request.Request object at 0x000000000512CD08&gt;</span></span><br><span class="line"><span class="comment"># &lt;class 'urllib.request.Request'&gt;</span></span><br><span class="line"><span class="comment"># [('Content-Type', 'image/jpeg'), ('Content-Length', '27784'), ('Connection', 'close'), ('Set-Cookie', '__cfduid=d40565824d114929f762f0330755fd5c91604544653; ...</span></span><br><span class="line"><span class="comment"># b'\xff\xd8\xff\xe0\x00\x10JFIF\x00\x01\x01\x00\x00\x01\x00\x01\x00\x00\xff\xdb\x00C...</span></span><br></pre></td></tr></tbody></table></figure>
<p>但此时爬取p站比如<code>https://i.pximg.net/img-original/img/2020/10/28/00/04/57/85281729_p0.jpg</code>仍然会是<code>HTTP Error 403: Forbidden</code>, 此时我们需要使用requests给p站增加<code>Referer</code>，参考carry_1024的文章：<a target="_blank" rel="noopener" href="https://blog.csdn.net/ycarry2017/article/details/79599539">https://blog.csdn.net/ycarry2017/article/details/79599539</a></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 若有访问该网站弹出证书不受信任时，直接忽略</span></span><br><span class="line"><span class="keyword">import</span> ssl</span><br><span class="line">ssl._create_default_https_context = ssl._create_unverified_context</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="comment">## 增加请求头，此处用到了Opener方法</span></span><br><span class="line">opener = urllib.request.build_opener()</span><br><span class="line">opener.addheaders=[(<span class="string">'Referer'</span>, <span class="string">"https://www.pixiv.net/member_illust.php?mode=medium&amp;illust_id=60541651"</span>)]</span><br><span class="line">urllib.request.install_opener(opener)</span><br><span class="line"></span><br><span class="line">url = <span class="string">"https://i.pximg.net/img-original/img/2020/10/28/00/04/57/85281729_p0.jpg"</span></span><br><span class="line"><span class="comment">## Copy a network object denoted by a URL to a local file. 复制网络文件到本地</span></span><br><span class="line">urllib.request.urlretrieve(url,<span class="string">"D://acg-girl.jpg"</span>)</span><br><span class="line"><span class="comment"># ('D://acg-girl.jpg', &lt;http.client.HTTPMessage at 0x535de48&gt;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## headers增加Referer参数后，getPage也可正常运行</span></span><br><span class="line">headers = {</span><br><span class="line">    <span class="string">'USER-AGENT'</span>:<span class="string">'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.111 Safari/537.36'</span>,</span><br><span class="line">    <span class="string">'Referer'</span>: <span class="string">"https://www.pixiv.net/member_illust.php?mode=medium&amp;illust_id=60541651"</span></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<h2 id="url解析parse"><a class="markdownIt-Anchor" href="#url解析parse"></a> URL解析Parse</h2>
<p>接下来我们来学习一下urllib的parse模块，该模块用于对网址进行非常方便的操作。</p>
<p>Parse module supports the following URL schemes:</p>
<p>file, ftp, gopher, hdl, http, https, imap, mailto, mms, news, nntp, prospero, rsync, rtsp, rtspu, sftp, shttp, sip, sips, snews, svn, svn+ssh, telnet, wais, ws, wss.</p>
<p>也就是几乎支持所有internet协议。</p>
<p><img src="https://i.imgur.com/qLWeGRZ.png" alt="Imgur"></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlparse <span class="keyword">as</span> pr</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlunparse <span class="keyword">as</span> upr</span><br><span class="line"></span><br><span class="line"><span class="comment"># scheme://netloc/path;parameters?query#fragment</span></span><br><span class="line">result = pr(<span class="string">'http://www.xiami.com/play?ids=/song/playlist/id/1/type/9#loadedt'</span>)</span><br><span class="line">result.hostname</span><br><span class="line"><span class="comment"># 'www.xiami.com'</span></span><br><span class="line">print(type(result),result)</span><br><span class="line"><span class="comment"># &lt;class 'urllib.parse.ParseResult'&gt; </span></span><br><span class="line"><span class="comment"># ParseResult(scheme='http', netloc='www.xiami.com', path='/play', \</span></span><br><span class="line"><span class="comment">#                      params='', query='ids=/song/playlist/id/1/type/9', fragment='loadedt')</span></span><br><span class="line">[print(result[i]) <span class="keyword">for</span> i <span class="keyword">in</span> range(len(result))]</span><br><span class="line"><span class="comment"># http</span></span><br><span class="line"><span class="comment"># www.xiami.com</span></span><br><span class="line"><span class="comment"># /play</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># ids=/song/playlist/id/1/type/9</span></span><br><span class="line"><span class="comment"># loaded</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 若要得到正确的nerloc值，url必须以//开头，否则会被算到path值里去</span></span><br><span class="line">print(pr(<span class="string">'www.xiami.com/play?ids=/song/playlist/id/1/type/9#loadedt'</span>,scheme=<span class="string">"https"</span>))</span><br><span class="line"><span class="comment"># ParseResult(scheme='https', netloc='', path='www.xiami.com/play',\</span></span><br><span class="line"><span class="comment">#                     params='', query='ids=/song/playlist/id/1/type/9', fragment='loadedt')</span></span><br><span class="line">print(pr(<span class="string">'https://www.xiami.com/play?ids=/song/playlist/id/1/type/9#loadedt'</span>,scheme=<span class="string">"http"</span>,allow_fragments=<span class="literal">False</span>))</span><br><span class="line"><span class="comment"># ParseResult(scheme='https', netloc='www.xiami.com', path='/play', \</span></span><br><span class="line"><span class="comment">#             params='', query='ids=/song/playlist/id/1/type/9#loadedt', fragment='')</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 将urlparse()分解的元素再拼合还原为一个url</span></span><br><span class="line">data = [result.scheme, result.netloc, result.path,result.params, result.query,result.fragment]</span><br><span class="line">print(upr(data))</span><br><span class="line"><span class="comment"># http://www.xiami.com/play?ids=/song/playlist/id/1/type/9#loadedt</span></span><br></pre></td></tr></tbody></table></figure>
<p><code>urlsplit</code>与<code>urlparse</code>l类似，但不包括params。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlsplit <span class="keyword">as</span> sp</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlunsplit <span class="keyword">as</span> usp</span><br><span class="line"></span><br><span class="line"><span class="comment"># # scheme://netloc/path?query#fragment</span></span><br><span class="line">result = sp(<span class="string">'http://www.xiami.com/play?ids=/song/playlist/id/1/type/9#loadedt'</span>)</span><br><span class="line">print(type(result),result)</span><br><span class="line"><span class="comment"># &lt;class 'urllib.parse.SplitResult'&gt; </span></span><br><span class="line"><span class="comment"># SplitResult(scheme='http', netloc='www.xiami.com', path='/play', \</span></span><br><span class="line"><span class="comment">#              query='ids=/song/playlist/id/1/type/9', fragment='loadedt')</span></span><br><span class="line">data = [result.scheme, result.netloc, result.path, result.query,result.fragment]</span><br><span class="line">print(usp(data))</span><br><span class="line"><span class="comment"># http://www.xiami.com/play?ids=/song/playlist/id/1/type/9#loadedt</span></span><br></pre></td></tr></tbody></table></figure>
<p><code>urljoin</code>函数用于构造一个绝对url，当参数中的url为绝对路径的URL(即以//或scheme://开始)，那么url的hostname和scheme将会出现在结果中</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urljoin <span class="keyword">as</span> jo</span><br><span class="line"> </span><br><span class="line">print(jo(<span class="string">"http://www.xiami.com/"</span>,<span class="string">"play?ids=/song/playlist/id/1/type/9#loadedt"</span>))</span><br><span class="line">print(jo(<span class="string">"http://www.xiami.com/play?ids=/song/playlist/"</span>,<span class="string">"play?ids=/song/playlist/id/1/type/9#loadedt"</span>))</span><br><span class="line">print(jo(<span class="string">"http:"</span>,<span class="string">"//www.xiami.com/play?ids=/song/playlist/id/1/type/9#loadedt"</span>))</span><br><span class="line"><span class="comment"># http://www.xiami.com/play?ids=/song/playlist/id/1/type/9#loadedt</span></span><br></pre></td></tr></tbody></table></figure>
<p>其他，<code>urlencode</code>类</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlencode, parse_qs, quote, unquote</span><br><span class="line"></span><br><span class="line">params = {</span><br><span class="line">    <span class="string">'tn'</span>:<span class="string">'baidu'</span>,</span><br><span class="line">    <span class="string">'wd'</span>: <span class="string">'google chrome'</span>,</span><br><span class="line">}</span><br><span class="line">base_url = <span class="string">'http://www.baidu.com/s?'</span></span><br><span class="line">base_url + urlencode(params)</span><br><span class="line"><span class="comment"># 'http://www.baidu.com/s?tn=baidu&amp;wd=google+chrome'</span></span><br><span class="line"></span><br><span class="line">print(parse_qs(urlencode(params)))</span><br><span class="line"><span class="comment"># {'tn': ['baidu'], 'wd': ['google chrome']}</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">'https://www.baidu.com/s?wd='</span> + quote(<span class="string">"百度"</span>)</span><br><span class="line"><span class="comment"># 'https://www.baidu.com/s?wd=%E7%99%BE%E5%BA%A6'</span></span><br><span class="line"></span><br><span class="line">url = <span class="string">'https://www.baidu.com/s?wd=%E7%99%BE%E5%BA%A6'</span></span><br><span class="line">print(unquote(url))</span><br><span class="line"><span class="comment"># https://www.baidu.com/s?wd=百度</span></span><br></pre></td></tr></tbody></table></figure>
<h2 id="错误处理error"><a class="markdownIt-Anchor" href="#错误处理error"></a> 错误处理Error</h2>
<p>我们对网页发起http请求时, 难免会遇到很多错误，比如404，连接超时，拒绝访问等，此时我们可以用urllib的error模块对异常进行处理。<br>
异常处理主要用到两个类，<code>urllib.error.URLError</code>和<code>urllib.error.HTTPError</code>。</p>
<ul>
<li>
<p>URLError 是 urllib.error 异常类的基类, 可以捕获由urllib.request 产生的异常。具有一个属性<code>reason</code>，即返回错误的原因。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> error</span><br><span class="line"></span><br><span class="line">url = <span class="string">"https://www.google.com"</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response = request.urlopen(url)</span><br><span class="line"><span class="keyword">except</span> error.URLError <span class="keyword">as</span> e:</span><br><span class="line">    print(e.reason)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># [WinError 10060] 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。</span></span><br></pre></td></tr></tbody></table></figure>
</li>
<li>
<p>HTTPError 专门处理 HTTP 和 HTTPS 请求的错误，有三个属性。</p>
<ul>
<li><code>code</code>：HTTP 请求返回的状态码。</li>
<li><code>reason</code>：与父类用法一样，表示返回错误的原因。</li>
<li><code>headers</code>：HTTP 请求返回的响应头信息。</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request,error</span><br><span class="line"></span><br><span class="line">url = <span class="string">"https://www.google.com"</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response = request.urlopen(url)</span><br><span class="line"><span class="keyword">except</span> error.HTTPError <span class="keyword">as</span> e:</span><br><span class="line">    print(<span class="string">'code: '</span> + e.code + <span class="string">'\n'</span>)</span><br><span class="line">    print(<span class="string">'reason: '</span> + e.reason + <span class="string">'\n'</span>)</span><br><span class="line">    print(<span class="string">'headers: '</span> + e.headers + <span class="string">'\n'</span>)</span><br><span class="line"><span class="comment"># TimeoutError                              Traceback (most recent call last)</span></span><br><span class="line">...</span><br><span class="line"><span class="comment"># URLError: &lt;urlopen error [WinError 10060] 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。&gt;</span></span><br></pre></td></tr></tbody></table></figure>
</li>
</ul>
<p>我们这里创建了一个getInfo函数，用于处理异常。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request, parse, error</span><br><span class="line"></span><br><span class="line">headers = {</span><br><span class="line">    <span class="string">'User-Agent'</span>:<span class="string">' Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36'</span>,</span><br><span class="line">    <span class="string">'Host'</span>: <span class="string">'httpbin.org'</span></span><br><span class="line">}</span><br><span class="line">dict = {</span><br><span class="line">    <span class="string">'words1'</span>: <span class="string">'you\'re a miracle'</span> ,</span><br><span class="line">    <span class="string">'words2'</span>:<span class="string">'what do you fear'</span></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getInfo</span>(<span class="params">url, data=<span class="string">""</span>, headers={}, method=<span class="string">"GET"</span>,timeout=<span class="number">1</span></span>):</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        dat = bytes(parse.urlencode(data), encoding=<span class="string">'utf8'</span>)</span><br><span class="line">        req = request.Request(url=url, data=dat, headers=headers, method=method) </span><br><span class="line">        req = request.urlopen(req, timeout=timeout)</span><br><span class="line">        print(req.read().decode(<span class="string">'utf-8'</span>))</span><br><span class="line">    <span class="keyword">except</span> error.HTTPError <span class="keyword">as</span> e:</span><br><span class="line">        print(e.reason, e.code, e.headers, sep=<span class="string">'\n'</span>)</span><br><span class="line">    <span class="keyword">except</span> error.URLError <span class="keyword">as</span> e:</span><br><span class="line">        <span class="keyword">if</span> isinstance(e.reason, socket.timeout):</span><br><span class="line">            print(<span class="string">'TIME OUT'</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">getInfo(<span class="string">"http://httpbin.org/post"</span>,dict,headers,<span class="string">"POST"</span>,<span class="number">5</span>)</span><br><span class="line"><span class="comment"># {</span></span><br><span class="line"><span class="comment">#   "args": {}, </span></span><br><span class="line"><span class="comment">#   "data": "", </span></span><br><span class="line"><span class="comment">#   "files": {}, </span></span><br><span class="line"><span class="comment">#   "form": {</span></span><br><span class="line"><span class="comment">#     "words1": "you're a miracle", </span></span><br><span class="line"><span class="comment">#     "words2": "what do you fear"</span></span><br><span class="line"><span class="comment">#   }, </span></span><br><span class="line"><span class="comment">#   "headers": {</span></span><br><span class="line"><span class="comment">#     "Accept-Encoding": "identity", </span></span><br><span class="line"><span class="comment">#     "Connection": "close", </span></span><br><span class="line"><span class="comment">#     "Content-Length": "49", </span></span><br><span class="line"><span class="comment">#     "Content-Type": "application/x-www-form-urlencoded", </span></span><br><span class="line"><span class="comment">#     "Host": "httpbin.org", </span></span><br><span class="line"><span class="comment">#     "User-Agent": "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36"</span></span><br><span class="line"><span class="comment">#   }, </span></span><br><span class="line"><span class="comment">#   "json": null, </span></span><br><span class="line"><span class="comment">#   "origin": "183.246.20.118", </span></span><br><span class="line"><span class="comment">#   "url": "http://httpbin.org/post"</span></span><br><span class="line"><span class="comment"># }</span></span><br><span class="line"></span><br><span class="line">getInfo(<span class="string">'http://httpbin.org/get'</span>)</span><br><span class="line"><span class="comment"># {</span></span><br><span class="line"><span class="comment">#   "args": {}, </span></span><br><span class="line"><span class="comment">#   "headers": {</span></span><br><span class="line"><span class="comment">#     "Accept-Encoding": "identity", </span></span><br><span class="line"><span class="comment">#     "Connection": "close", </span></span><br><span class="line"><span class="comment">#     "Content-Type": "application/x-www-form-urlencoded", </span></span><br><span class="line"><span class="comment">#     "Host": "httpbin.org", </span></span><br><span class="line"><span class="comment">#     "User-Agent": "Python-urllib/3.6"</span></span><br><span class="line"><span class="comment">#   }, </span></span><br><span class="line"><span class="comment">#   "origin": "183.246.20.118", </span></span><br><span class="line"><span class="comment">#   "url": "http://httpbin.org/get"</span></span><br><span class="line"><span class="comment"># }</span></span><br><span class="line"></span><br><span class="line">getInfo(<span class="string">'http://httpbin.org/get'</span>,timeout=<span class="number">.1</span>)</span><br><span class="line"><span class="comment"># TIME OUT</span></span><br><span class="line">getInfo(<span class="string">'http://httpbin.org/index.htm'</span>)</span><br><span class="line"><span class="comment"># NOT FOUND</span></span><br><span class="line"><span class="comment"># 404</span></span><br><span class="line"><span class="comment"># Connection: close</span></span><br><span class="line"><span class="comment"># Server: meinheld/0.6.1</span></span><br><span class="line"><span class="comment"># Date: Sun, 11 Mar 2018 06:25:37 GMT</span></span><br><span class="line"><span class="comment"># Content-Type: text/html</span></span><br><span class="line"><span class="comment"># Content-Length: 233</span></span><br><span class="line"><span class="comment"># Access-Control-Allow-Origin: *</span></span><br><span class="line"><span class="comment"># Access-Control-Allow-Credentials: true</span></span><br><span class="line"><span class="comment"># X-Powered-By: Flask</span></span><br><span class="line"><span class="comment"># X-Processed-Time: 0</span></span><br><span class="line"><span class="comment"># Via: 1.1 vegur</span></span><br></pre></td></tr></tbody></table></figure>
<h2 id="handler"><a class="markdownIt-Anchor" href="#handler"></a> Handler</h2>
<p>如果我们需要在请求中添加代理proxy、处理Cookies，就需要用到<code>Handler</code>和<code>OpenerDirector</code>。</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://docs.python.org/3/library/urllib.request.html#urllib.request.BaseHandler">https://docs.python.org/3/library/urllib.request.html#urllib.request.BaseHandler</a></p>
</blockquote>
<p>Handler 能处理请求（HTTP、HTTPS、FTP等）中的各种事情。其常见的类有：</p>
<ul>
<li>
<p><code>HTTPDefaultErrorHandler</code>：处理 HTTP 响应错误。</p>
</li>
<li>
<p><code>HTTPRedirectHandler</code>：处理 HTTP 重定向。</p>
</li>
<li>
<p><code>HTTPCookieProcessor</code>(<em>cookiejar=None</em>)：处理 HTTP 请求中的 Cookies</p>
</li>
<li>
<p><code>ProxyHandler</code>(<em>proxies=None</em>)：设置代理</p>
</li>
<li>
<p><code>HTTPPasswordMgr</code>：用于管理密码，它维护了用户名密码的表。</p>
</li>
<li>
<p><code>HTTPBasicAuthHandler</code>：用于登录认证，一般和 <code>HTTPPasswordMgr</code> 结合使用。</p>
</li>
<li>
<p><code>HTTPPasswordMgrWithDefaultRealm</code></p>
</li>
<li>
<p><code>HTTPPasswordMgrWithPriorAuth</code></p>
</li>
<li>
<p><code>...</code></p>
</li>
</ul>
<p>对于 OpenerDirector，之前用过 urlopen() 这个方法，实际上它就是 urllib 为我们提供的一个Opener。</p>
<p>opener 对象由 build_opener(handler) 方法来创建出来 。创建自定义的 opener，需要使用 <code>install_opener(opener)</code>方法。</p>
<h3 id="使用代理proxy"><a class="markdownIt-Anchor" href="#使用代理proxy"></a> 使用代理Proxy</h3>
<p>有些网站做了浏览频率限制或者禁止了你的IP请求。这个时候就需要我们使用代理来突破这“枷锁”，让对方服务器误以为我们是不同的用户发起的http请求。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.error <span class="keyword">import</span> URLError</span><br><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> ProxyHandler, build_opener,install_opener</span><br><span class="line"></span><br><span class="line">url = <span class="string">"http://tieba.baidu.com/"</span></span><br><span class="line">headers = {</span><br><span class="line">    <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36'</span></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">proxy_handler = ProxyHandler({</span><br><span class="line">   <span class="string">'http'</span>: <span class="string">'web-proxy.oa.com:8080'</span>,</span><br><span class="line">    <span class="string">'https'</span>: <span class="string">'web-proxy.oa.com:8080'</span></span><br><span class="line">})</span><br><span class="line"></span><br><span class="line">opener = build_opener(proxy_handler)</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="comment"># urllib.request.install_opener(opener)</span></span><br><span class="line">    <span class="comment"># request = urllib.request.Request(url=url, headers=headers)</span></span><br><span class="line">    <span class="comment"># response = urllib.request.urlopen(request)</span></span><br><span class="line">    response = opener.open(<span class="string">'https://www.baidu.com'</span>)</span><br><span class="line">    print(response.read().decode(<span class="string">'utf-8'</span>))</span><br><span class="line"><span class="keyword">except</span> URLError <span class="keyword">as</span> e:</span><br><span class="line">    print(e.reason)</span><br></pre></td></tr></tbody></table></figure>
<p>我们也可以使用requests模块进行更方便的proxy代理处理。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"> </span><br><span class="line">proxies = {</span><br><span class="line">    <span class="string">'http'</span>: <span class="string">'url'</span>,</span><br><span class="line">    <span class="string">'https'</span>: <span class="string">'url'</span></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">## http://user:password@host:port</span></span><br><span class="line">proxies = {</span><br><span class="line">    <span class="string">'http'</span>: <span class="string">'socks5://user:password@host:port'</span>,</span><br><span class="line">    <span class="string">'https'</span>: <span class="string">'socks5://user:password@host:port'</span></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">requests.get(<span class="string">"https://www.baidu.com"</span>, proxies=proxies)</span><br></pre></td></tr></tbody></table></figure>
<h3 id="认证登录auth"><a class="markdownIt-Anchor" href="#认证登录auth"></a> 认证登录Auth</h3>
<p>有些网站需要登录之后才能继续浏览网页,这时就需要用到认证登录。</p>
<p>我们可以使用 HTTPPasswordMgrWithDefaultRealm() 实例化一个账号密码管理对象，然后使用 add_password() 函数添加账号和密码；接着使用 HTTPBasicAuthHandler() 得到 hander；再使用 build_opener() 获取 opener 对象；最后使用 opener 的 open() 函数发起请求。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> HTTPPasswordMgrWithDefaultRealm, HTTPBasicAuthHandler, build_opener</span><br><span class="line"><span class="keyword">from</span> urllib.error <span class="keyword">import</span> URLError</span><br><span class="line"></span><br><span class="line">url = <span class="string">"http://tieba.baidu.com/"</span></span><br><span class="line">user = <span class="string">'user'</span></span><br><span class="line">password = <span class="string">'password'</span></span><br><span class="line">pwdmgr = HTTPPasswordMgrWithDefaultRealm()</span><br><span class="line">pwdmgr.add_password(<span class="literal">None</span>, url, user, password)</span><br><span class="line">auth_handler = HTTPBasicAuthHandler(pwdmgr)</span><br><span class="line">opener = build_opener(auth_handler)</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    result = opener.open(url)</span><br><span class="line">    html = result.read().decode(<span class="string">'utf-8'</span>)</span><br><span class="line">    print(html)</span><br><span class="line"><span class="keyword">except</span> URLError <span class="keyword">as</span> e:</span><br><span class="line">    print(e.reason)</span><br></pre></td></tr></tbody></table></figure>
<h3 id="cookies设置"><a class="markdownIt-Anchor" href="#cookies设置"></a> Cookies设置</h3>
<p>如果请求的页面每次需要身份验证，我们可以使用 Cookies 来自动登录，免去重复登录验证的操作。</p>
<p>获取 Cookies 需要使用 http.cookiejar.CookieJar() 实例化一个 Cookies 对象, 再用 urllib.request.HTTPCookieProcessor 构建出 handler 对象,最后使用 opener 的 open() 函数即可。</p>
<p>这个例子是获取请求百度的 Cookies 并保存到文件中，代码如下：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> http.cookiejar</span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">url = <span class="string">'http://www.baidu.com'</span></span><br><span class="line">fileName = <span class="string">'cookie.txt'</span></span><br><span class="line"></span><br><span class="line">cookie = http.cookiejar.CookieJar()</span><br><span class="line">handler = urllib.request.HTTPCookieProcessor(cookie)</span><br><span class="line">opener = urllib.request.build_opener(handler)</span><br><span class="line">response = opener.open(url)</span><br><span class="line">print(response)</span><br><span class="line"><span class="comment"># &lt;http.client.HTTPResponse object at 0x04D421F0&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> cookie:</span><br><span class="line">    print(item.name+<span class="string">"="</span>+item.value)</span><br><span class="line"><span class="comment"># BAIDUID=7A55D7DB4ECB570361D1D1186DD85275:FG=1</span></span><br><span class="line"><span class="comment"># ...</span></span><br><span class="line"></span><br><span class="line">f = open(fileName,<span class="string">'a'</span>)</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> cookie:</span><br><span class="line">    f.write(item.name + <span class="string">" = "</span> + item.value + <span class="string">'\n'</span>)</span><br><span class="line">f.close()</span><br></pre></td></tr></tbody></table></figure>
<p>也可使用 http.cookiejar.LWPCookieJar 或者http.cookiejar.MozillaCookieJar构建：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">filename = <span class="string">'cookies.txt'</span></span><br><span class="line">cookie = http.cookiejar.LWPCookieJar(filename) <span class="comment"># cookie = http.cookiejar.MozillaCookieJar(filename)</span></span><br><span class="line">handler = urllib.request.HTTPCookieProcessor(cookie)</span><br><span class="line">opener = urllib.request.build_opener(handler)</span><br><span class="line"></span><br><span class="line">response = opener.open(url)</span><br><span class="line">cookie.save(ignore_discard=<span class="literal">True</span>, ignore_expires=<span class="literal">True</span>)</span><br><span class="line"><span class="comment">## LWP-Cookies-2.0</span></span><br><span class="line"><span class="comment"># Set-Cookie3: BAIDUID="990E47C14A144D813BB6629BEA0D1BEF:FG=1"; path="/"; domain=".baidu.com"; path_spec; domain_dot; expires="2086-03-29 08:56:02Z"; version=0</span></span><br><span class="line"><span class="comment"># ...</span></span><br></pre></td></tr></tbody></table></figure>
<p>然后我们可以读取cookie文件：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cookie = http.cookiejar.LWPCookieJar()</span><br><span class="line">cookie.load(<span class="string">'cookies.txt'</span>, ignore_discard=<span class="literal">True</span>, ignore_expires=<span class="literal">True</span>)</span><br><span class="line">handler = urllib.request.HTTPCookieProcessor(cookie)</span><br><span class="line">opener = urllib.request.build_opener(handler)</span><br><span class="line">response = opener.open(<span class="string">'http://www.baidu.com'</span>)</span><br><span class="line">print(response.read().decode(<span class="string">'utf-8'</span>))</span><br><span class="line"><span class="comment"># &lt;!DOCTYPE html&gt;</span></span><br><span class="line"><span class="comment"># &lt;!--STATUS OK--&gt;</span></span><br><span class="line"><span class="comment"># ...</span></span><br></pre></td></tr></tbody></table></figure>
<h2 id="robots"><a class="markdownIt-Anchor" href="#robots"></a> Robots</h2>
<p>先列举一个robots.txt，以淘宝为例;</p>
<p><a target="_blank" rel="noopener" href="https://www.taobao.com/robots.txt">https://www.taobao.com/robots.txt</a></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">User-agent:  Baiduspider</span><br><span class="line">Allow:  /article</span><br><span class="line">Allow:  /oshtml</span><br><span class="line">Disallow:  /product/</span><br><span class="line">Disallow:  /</span><br><span class="line"></span><br><span class="line">User-Agent:  Googlebot</span><br><span class="line">Allow:  /article</span><br><span class="line">Allow:  /oshtml</span><br><span class="line">Allow:  /product</span><br><span class="line">Allow:  /spu</span><br><span class="line">Allow:  /dianpu</span><br><span class="line">Allow:  /oversea</span><br><span class="line">Allow:  /list</span><br><span class="line">Disallow:  /</span><br><span class="line"></span><br><span class="line">User-agent:  Bingbot</span><br><span class="line">Allow:  /article</span><br><span class="line">Allow:  /oshtml</span><br><span class="line">Allow:  /product</span><br><span class="line">Allow:  /spu</span><br><span class="line">Allow:  /dianpu</span><br><span class="line">Allow:  /oversea</span><br><span class="line">Allow:  /list</span><br><span class="line">Disallow:  /</span><br><span class="line"></span><br><span class="line">User-Agent:  <span class="number">360</span>Spider</span><br><span class="line">Allow:  /article</span><br><span class="line">Allow:  /oshtml</span><br><span class="line">Disallow:  /</span><br><span class="line"></span><br><span class="line">User-Agent:  Yisouspider</span><br><span class="line">Allow:  /article</span><br><span class="line">Allow:  /oshtml</span><br><span class="line">Disallow:  /</span><br><span class="line"></span><br><span class="line">User-Agent:  Sogouspider</span><br><span class="line">Allow:  /article</span><br><span class="line">Allow:  /oshtml</span><br><span class="line">Allow:  /product</span><br><span class="line">Disallow:  /</span><br><span class="line"></span><br><span class="line">User-Agent:  Yahoo!  Slurp</span><br><span class="line">Allow:  /product</span><br><span class="line">Allow:  /spu</span><br><span class="line">Allow:  /dianpu</span><br><span class="line">Allow:  /oversea</span><br><span class="line">Allow:  /list</span><br><span class="line">Disallow:  /</span><br><span class="line"></span><br><span class="line">User-Agent:  *</span><br><span class="line">Disallow:  /</span><br></pre></td></tr></tbody></table></figure>
<p>解析robots.txt，我们需要用到RobotFileParser。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.robotparser <span class="keyword">import</span> RobotFileParser</span><br><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</span><br><span class="line"></span><br><span class="line">url = <span class="string">"http://httpbin.org/robots.txt "</span></span><br><span class="line"></span><br><span class="line">rp = RobotFileParser(url)</span><br><span class="line">rp.read()</span><br><span class="line">print(rp.can_fetch(<span class="string">'*'</span>, <span class="string">'http://httpbin.org/deny'</span>))</span><br><span class="line">print(rp.can_fetch(<span class="string">'*'</span>, <span class="string">"http://httpbin.org/image"</span>))</span><br><span class="line"><span class="comment"># False</span></span><br><span class="line"><span class="comment"># True</span></span><br></pre></td></tr></tbody></table></figure>
<h2 id="faq"><a class="markdownIt-Anchor" href="#faq"></a> FAQ</h2>
<p><strong>HTTP Error 403: Forbidden</strong></p>
<ol>
<li>
<p>将请求加以包装，变成浏览器请求模式</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">headers = {</span><br><span class="line">    <span class="string">'USER-AGENT'</span>:<span class="string">'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.111 Safari/537.36'</span></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
</li>
<li>
<p>降低请求频率，每次请求时暂停短暂时间/用不同的IP进行访问</p>
</li>
<li>
<p>复制请求网址到浏览器进行检查，如仍然为<code>403 Forbidden</code>,检查请求网址是否有误或者过时。</p>
</li>
<li>
<p>参考：python 爬虫禁止访问解决方法（403）： <a target="_blank" rel="noopener" href="https://blog.csdn.net/u011808673/article/details/80609221">https://blog.csdn.net/u011808673/article/details/80609221</a></p>
</li>
</ol>
<h2 id="references"><a class="markdownIt-Anchor" href="#references"></a> REFERENCES</h2>
<ul>
<li>
<p><a target="_blank" rel="noopener" href="https://docs.python.org/3/library/urllib.html">https://docs.python.org/3/library/urllib.html</a></p>
<p>-<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/urllib.request.html">https://docs.python.org/3/library/urllib.request.html</a></p>
</li>
<li>
<p><a target="_blank" rel="noopener" href="http://httpbin.org/">http://httpbin.org/</a></p>
</li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">Joaxin</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://u.pinsflora.xyz/Pysnista/Crawler/Py_Crawler02_urllib/">https://u.pinsflora.xyz/Pysnista/Crawler/Py_Crawler02_urllib/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Crawler/">Crawler</a></div><div class="post_share"><div class="addtoany"><div class="a2a_kit a2a_kit_size_32 a2a_default_style"><a class="a2a_button_facebook"></a><a class="a2a_button_twitter"></a><a class="a2a_button_wechat"></a><a class="a2a_button_sina_weibo"></a><a class="a2a_button_facebook_messenger"></a><a class="a2a_button_email"></a><a class="a2a_button_copy_link"></a><a class="a2a_dd" target="_blank" rel="noopener" href="https://www.addtoany.com/share"></a></div></div><script async="async" src="https://static.addtoany.com/menu/page.js"></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/Pysnista/Crawler/py_Crawler04_XPath/"><img class="prev-cover" src="https://cdn.jsdelivr.net/gh/joaxin/img_bed/img/cover_posts/crawler/requests.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">Python Web Crawler Vol.4 -  Xpath &amp; PyQuery</div></div></a></div><div class="next-post pull-right"><a href="/Pysnista/Crawler/Py_Crawler03_beautifulsoup4/"><img class="next-cover" src="https://cdn.jsdelivr.net/gh/joaxin/img_bed/img/cover_posts/crawler/beautifulsoup4.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">Python Web Crawler Pt.3 - Beautiful Soup</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> Related Articles</span></div><div class="relatedPosts-list"><div><a href="/Pysnista/Crawler/Crawler/py_Crawler_examples/" title="Python Web Crawler"><img class="cover" src="https://cdn.jsdelivr.net/gh/joaxin/img_bed/img/cover/cover_books.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="fas fa-history fa-fw"></i> 2020-05-01</div><div class="title">Python Web Crawler</div></div></a></div><div><a href="/Pysnista/Crawler/Crawler/py_Crawler_xiami/" title="Xiami Jazz - Hiphop Artists"><img class="cover" src="https://cdn.jsdelivr.net/gh/joaxin/img_bed/img/cover/cover_writing-letters-french.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="fas fa-history fa-fw"></i> 2018-03-15</div><div class="title">Xiami Jazz - Hiphop Artists</div></div></a></div><div><a href="/Pysnista/Crawler/Crawler/py_Crawler_google/" title="Python Web Crawler - Google"><img class="cover" src="https://cdn.jsdelivr.net/gh/joaxin/img_bed/img/cover/cover_stars_man_orchard_photos.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="fas fa-history fa-fw"></i> 2018-04-15</div><div class="title">Python Web Crawler - Google</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="https://avatars2.githubusercontent.com/u/8346164?s=460&amp;v=4" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">Joaxin</div><div class="author-info__description">When I close my eyes, I'm in my own ♡cean 🐟aves.</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">340</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">110</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">34</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/joaxin"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/joaxin" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:lotility@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="/atom.xml" target="_blank" title="RSS"><i class="fas fa-rss"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">感謝訪問本站，若喜歡請收藏 ^_^</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#http%E8%AF%B7%E6%B1%82request"><span class="toc-number">1.</span> <span class="toc-text"> HTTP请求Request</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#url%E8%A7%A3%E6%9E%90parse"><span class="toc-number">2.</span> <span class="toc-text"> URL解析Parse</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86error"><span class="toc-number">3.</span> <span class="toc-text"> 错误处理Error</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#handler"><span class="toc-number">4.</span> <span class="toc-text"> Handler</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E4%BB%A3%E7%90%86proxy"><span class="toc-number">4.1.</span> <span class="toc-text"> 使用代理Proxy</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%A4%E8%AF%81%E7%99%BB%E5%BD%95auth"><span class="toc-number">4.2.</span> <span class="toc-text"> 认证登录Auth</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cookies%E8%AE%BE%E7%BD%AE"><span class="toc-number">4.3.</span> <span class="toc-text"> Cookies设置</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#robots"><span class="toc-number">5.</span> <span class="toc-text"> Robots</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#faq"><span class="toc-number">6.</span> <span class="toc-text"> FAQ</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#references"><span class="toc-number">7.</span> <span class="toc-text"> REFERENCES</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/Lang/es/duo_es/" title="No title"><img src="https://cdn.jsdelivr.net/gh/joaxin/img_bed/img/cover/cover_seeds.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="No title"/></a><div class="content"><a class="title" href="/Lang/es/duo_es/" title="No title">No title</a><time datetime="2020-06-29T03:44:49.224Z" title="Created 2020-06-29 11:44:49">2020-06-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/Lang/kl/duo_kl001_intro/" title="Klingon- Vol.1 - Introduction"><img src="https://cdn.jsdelivr.net/gh/joaxin/img_bed/img/cover/cover_little_girl_phone.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Klingon- Vol.1 - Introduction"/></a><div class="content"><a class="title" href="/Lang/kl/duo_kl001_intro/" title="Klingon- Vol.1 - Introduction">Klingon- Vol.1 - Introduction</a><time datetime="2020-06-26T16:00:00.000Z" title="Created 2020-06-27 00:00:00">2020-06-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/Life/apps/life_apps_android_list/" title="安卓 | 装机必备清单及习惯步骤"><img src="https://i.postimg.cc/KYPmhV8w/android-new-logo.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="安卓 | 装机必备清单及习惯步骤"/></a><div class="content"><a class="title" href="/Life/apps/life_apps_android_list/" title="安卓 | 装机必备清单及习惯步骤">安卓 | 装机必备清单及习惯步骤</a><time datetime="2020-06-20T04:29:10.462Z" title="Created 2020-06-20 12:29:10">2020-06-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/Pysnista/Intro/files/py_pillow/" title="Python - 操作图像"><img src="https://cdn.jsdelivr.net/gh/joaxin/img_bed/img/cover/cover_little_girl_phone.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Python - 操作图像"/></a><div class="content"><a class="title" href="/Pysnista/Intro/files/py_pillow/" title="Python - 操作图像">Python - 操作图像</a><time datetime="2020-05-02T16:00:00.000Z" title="Created 2020-05-03 00:00:00">2020-05-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/Pysnista/Intro/files/py_files_pdf_word/" title="Python - PDF &amp; Word"><img src="https://i.loli.net/2020/07/09/6ALoRXnITgcuvy2.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Python - PDF &amp; Word"/></a><div class="content"><a class="title" href="/Pysnista/Intro/files/py_files_pdf_word/" title="Python - PDF &amp; Word">Python - PDF &amp; Word</a><time datetime="2020-04-12T16:00:00.000Z" title="Created 2020-04-13 00:00:00">2020-04-13</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://cdn.pixabay.com/photo/2020/09/23/19/58/halloween-5596921__340.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By Joaxin</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Refine, the Life</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="Increase font size"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="Decrease font size"><i class="fas fa-minus"></i></button><button id="translateLink" type="button" title="Switch Between Traditional Chinese And Simplified Chinese">繁</button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="chat_btn" type="button" title="rightside.chat_btn"><i class="fas fa-sms"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (document.getElementsByClassName('mermaid').length) {
  if (window.mermaidJsLoad) mermaid.init()
  else {
    getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(() => {
      window.mermaidJsLoad = true
      mermaid.initialize({
        theme: 'default',
      })
      false && mermaid.init()
    })
  }
}</script></div><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="fasle"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script>(function(i,s,o,g,r,a,m){i["DaoVoiceObject"]=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;a.charset="utf-8";m.parentNode.insertBefore(a,m)})(window,document,"script",('https:' == document.location.protocol ? 'https:' : 'http:') + "//widget.daovoice.io/widget/fae45343.js","daovoice")
</script><script>var isChatBtn = true
daovoice('init', {
  app_id: 'fae45343',},{
  launcher: { 
     disableLauncherIcon: isChatBtn // 悬浮 ICON 是否显示
  },
});
daovoice('update');

if (isChatBtn) {
  var chatBtnFn = () => {
    var chatBtn = document.getElementById("chat_btn")
    chatBtn.addEventListener("click", function(){
      daovoice('show')
    });
  }
  chatBtnFn()
} else {
  if (true) {
    function chatBtnHide () {
      daovoice('update', {},{
        launcher: { 
        disableLauncherIcon: true // 悬浮 ICON 是否显示
        },
      });
    }
    function chatBtnShow () {
      daovoice('update', {},{
        launcher: { 
        disableLauncherIcon: false // 悬浮 ICON 是否显示
        },
      });
    }
  }
}</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>